{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNqhbESwSpGj"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/MDDdataset/symptom_sum_top16/train.pkl', 'rb') as f:\n",
        "      raw_train_data = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/MDDdataset/symptom_sum_top16/test.pkl', 'rb') as f:\n",
        "      raw_test_data = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/MDDdataset/symptom_sum_top16/val.pkl', 'rb') as f:\n",
        "      raw_val_data = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_data=pd.DataFrame(raw_train_data)\n",
        "test_data=pd.DataFrame(raw_test_data)\n",
        "val_data=pd.DataFrame(raw_val_data)"
      ],
      "metadata": {
        "id": "KzYOl5qkSriM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = pd.concat([train_data, val_data], axis=0)\n",
        "df_all = pd.concat([df_all, test_data], axis=0)"
      ],
      "metadata": {
        "id": "lT_tpK56StEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import f1_score, recall_score, confusion_matrix\n",
        "import numpy as np\n",
        "from sklearn.utils import resample\n",
        "\n",
        " # Update the path as necessary\n",
        "\n",
        "# Create a binary label for a specific disease (e.g., anxiety)\n",
        "df_all['has_disease'] = df_all['diseases'].apply(lambda x: 'anxiety' in x)  # Update the disease as needed\n",
        "\n",
        "# Extract features using CountVectorizer\n",
        "vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n",
        "X = vectorizer.fit_transform(df_all['selected_posts'].astype(str))\n",
        "y = df_all['has_disease']\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a logistic regression model on the training set\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Initialize lists to store the metrics\n",
        "f1_scores = []\n",
        "sensitivities = []\n",
        "specificities = []\n",
        "\n",
        "# Convert X_test and y_test to numpy arrays if not already (depends on your previous operations)\n",
        "X_test_np = X_test.toarray()  # Convert to numpy array if using sparse matrix from CountVectorizer\n",
        "y_test_np = np.array(y_test)  # Ensure y_test is a numpy array\n",
        "\n",
        "n_iterations=100\n",
        "\n",
        "# Bootstrap sampling and metric calculation\n",
        "for _ in range(n_iterations):\n",
        "    # Bootstrap sample the test data indices\n",
        "    indices = resample(np.arange(len(y_test_np)), replace=True)  # Generate indices for resampling\n",
        "    X_sample = X_test_np[indices]\n",
        "    y_sample = y_test_np[indices]\n",
        "    y_pred = model.predict(X_sample)\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    tn, fp, fn, tp = confusion_matrix(y_sample, y_pred).ravel()\n",
        "\n",
        "    # Calculate metrics\n",
        "    f1 = f1_score(y_sample, y_pred)\n",
        "    sensitivity = recall_score(y_sample, y_pred)\n",
        "    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
        "\n",
        "    # Store the metrics\n",
        "    f1_scores.append(f1)\n",
        "    sensitivities.append(sensitivity)\n",
        "    specificities.append(specificity)\n",
        "\n",
        "# Calculate the mean and standard deviation for each metric\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "mean_sensitivity = np.mean(sensitivities)\n",
        "std_sensitivity = np.std(sensitivities)\n",
        "mean_specificity = np.mean(specificities)\n",
        "std_specificity = np.std(specificities)\n",
        "\n",
        "# Print the results\n",
        "print(f\"F1 Score: Mean = {mean_f1:.3f}, Std = {std_f1:.3f}\")\n",
        "print(f\"Sensitivity: Mean = {mean_sensitivity:.3f}, Std = {std_sensitivity:.3f}\")\n",
        "print(f\"Specificity: Mean = {mean_specificity:.3f}, Std = {std_specificity:.3f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQFPLTFzS2_4",
        "outputId": "f28a1884-89e8-4504-93cf-cb6068ad0247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: Mean = 0.412, Std = 0.023\n",
            "Sensitivity: Mean = 0.321, Std = 0.021\n",
            "Specificity: Mean = 0.977, Std = 0.002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, recall_score, confusion_matrix\n",
        "import numpy as np\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Load your dataset\n",
        "# df_all = pd.read_csv('path_to_your_dataset.csv')  # Update the path as necessary\n",
        "\n",
        "# Names of the columns representing GAD-7 items\n",
        "gad7_columns = ['item1', 'item2', 'item3', 'item4', 'item5', 'item6', 'item7']  # Replace with your actual column names\n",
        "\n",
        "# Calculate the GAD-7 total score for each user\n",
        "df_all['gad7_score'] = df_all[gad7_columns].sum(axis=1)\n",
        "\n",
        "# Create a binary label for anxiety based on GAD-7 score (>=10 indicates GAD)\n",
        "df_all['has_disease'] = df_all['gad7_score'] >= 10\n",
        "\n",
        "# Extract features using CountVectorizer for the text data\n",
        "vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n",
        "X_text = vectorizer.fit_transform(df_all['selected_posts'].astype(str))\n",
        "\n",
        "# Use the GAD-7 total score as an additional feature\n",
        "X_gad7 = df_all[['gad7_score']].values\n",
        "\n",
        "# Combine text features and GAD-7 score\n",
        "X_combined = hstack([X_text, X_gad7])\n",
        "y = df_all['has_disease']\n",
        "\n",
        "# Initialize the 5-fold Stratified cross-validation\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store the metrics across folds\n",
        "f1_scores = []\n",
        "sensitivity_scores = []\n",
        "specificity_scores = []\n",
        "\n",
        "# Train and evaluate the model using 5-fold cross-validation\n",
        "for train_index, test_index in kf.split(X_combined, y):\n",
        "    X_train, X_test = X_combined[train_index], X_combined[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Train a logistic regression model\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test fold\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "    # Calculate metrics\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    sensitivity = recall_score(y_test, y_pred)\n",
        "    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
        "\n",
        "    # Store the metrics for this fold\n",
        "    f1_scores.append(f1)\n",
        "    sensitivity_scores.append(sensitivity)\n",
        "    specificity_scores.append(specificity)\n",
        "\n",
        "# Calculate the mean and standard deviation for each metric\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "mean_sensitivity = np.mean(sensitivity_scores)\n",
        "std_sensitivity = np.std(sensitivity_scores)\n",
        "mean_specificity = np.mean(specificity_scores)\n",
        "std_specificity = np.std(specificity_scores)\n",
        "\n",
        "# Print the results\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: Mean = {mean_f1:.3f}, Std = {std_f1:.3f}\")\n",
        "print(f\"Sensitivity: Mean = {mean_sensitivity:.3f}, Std = {std_sensitivity:.3f}\")\n",
        "print(f\"Specificity: Mean = {mean_specificity:.3f}, Std = {std_specificity:.3f}\")\n"
      ],
      "metadata": {
        "id": "7_bETrr37ReY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import f1_score, recall_score, confusion_matrix\n",
        "import numpy as np\n",
        "from sklearn.utils import resample\n",
        " # Update the path as necessary\n",
        "\n",
        "# Create a binary label for a specific disease (e.g., anxiety)\n",
        "df_all['has_disease'] = df_all['diseases'].apply(lambda x: 'anxiety' in x)  # Update the disease as needed\n",
        "\n",
        "# Extract features using CountVectorizer\n",
        "vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n",
        "X = vectorizer.fit_transform(df_all['selected_posts'].astype(str))\n",
        "y = df_all['has_disease']\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a logistic regression model on the training set\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "n_iterations = 1000\n",
        "\n",
        "# Initialize lists to store the metrics\n",
        "f1_scores = []\n",
        "sensitivities = []\n",
        "specificities = []\n",
        "\n",
        "# Convert X_test to numpy array if using sparse matrix from CountVectorizer\n",
        "X_test_np = X_test.toarray() if hasattr(X_test, \"toarray\") else X_test\n",
        "\n",
        "# Bootstrap sampling and metric calculation\n",
        "for _ in range(n_iterations):\n",
        "    # Bootstrap sample the test data indices\n",
        "    indices = resample(np.arange(len(y_test)), replace=True)  # Generate indices for resampling\n",
        "    X_sample = X_test_np[indices]\n",
        "    y_sample = y_test.iloc[indices].values  # Use .iloc for correct indexing\n",
        "    y_pred = model.predict(X_sample)\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    tn, fp, fn, tp = confusion_matrix(y_sample, y_pred).ravel()\n",
        "\n",
        "    # Calculate metrics\n",
        "    f1 = f1_score(y_sample, y_pred)\n",
        "    sensitivity = recall_score(y_sample, y_pred)\n",
        "    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
        "\n",
        "    # Store the metrics\n",
        "    f1_scores.append(f1)\n",
        "    sensitivities.append(sensitivity)\n",
        "    specificities.append(specificity)\n",
        "\n",
        "# Calculate the mean and standard deviation for each metric\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "mean_sensitivity = np.mean(sensitivities)\n",
        "std_sensitivity = np.std(sensitivities)\n",
        "mean_specificity = np.mean(specificities)\n",
        "std_specificity = np.std(specificities)\n",
        "\n",
        "# Print the results\n",
        "print(f\"F1 Score: Mean = {mean_f1:.3f}, Std = {std_f1:.3f}\")\n",
        "print(f\"Sensitivity: Mean = {mean_sensitivity:.3f}, Std = {std_sensitivity:.3f}\")\n",
        "print(f\"Specificity: Mean = {mean_specificity:.3f}, Std = {std_specificity:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrhKmnNvTVl7",
        "outputId": "88418ad0-bae7-4349-ab1e-6980d2da44ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: Mean = 0.409, Std = 0.024\n",
            "Sensitivity: Mean = 0.319, Std = 0.023\n",
            "Specificity: Mean = 0.977, Std = 0.002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gad7_keywords = [\n",
        "    \"nervousness\",\n",
        "    \"uncontrol\",\n",
        "    \"excess\",\n",
        "    \"relaxation\",\n",
        "    \"restlessness\",\n",
        "    \"irritability\",\n",
        "    \"fear\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "hUewgSje8hbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save\n",
        "with open('anxiety-chatgpt-logistic-model.pkl','wb') as f:\n",
        "    pickle.dump(model,f)\n",
        "\n",
        "# load\n",
        "with open('anxiety-chatgpt-logistic-model.pkl', 'rb') as f:\n",
        "    model_loaded = pickle.load(f)"
      ],
      "metadata": {
        "id": "NQp_4_Gkbs6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=model_loaded.predict(X_combined.tocsr()[0:10])"
      ],
      "metadata": {
        "id": "7KVixczBcVMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, recall_score, confusion_matrix\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Assuming df_all is your dataset\n",
        "# Example to ensure the setup matches expected structur\n",
        "\n",
        "# Convert lists in 'selected_posts' to single strings\n",
        "df_all['selected_posts'] = df_all['selected_posts'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
        "\n",
        "# Define keywords or phrases indicative of each GAD-7 item\n",
        "gad7_keywords = {\n",
        "    \"nervousness\": [\"nervous\", \"anxious\", \"on edge\"],\n",
        "    \"uncontrol\": [\"can't stop\", \"uncontrollable\"],\n",
        "    \"excess\": [\"too much\", \"excessive\", \"all the time\"],\n",
        "    \"relaxation\": [\"can't relax\", \"trouble relaxing\"],\n",
        "    \"restlessness\": [\"restless\", \"can't sit still\"],\n",
        "    \"irritability\": [\"annoyed\", \"irritable\"],\n",
        "    \"fear\": [\"afraid\", \"fearful\", \"something awful\"]\n",
        "}\n",
        "\n",
        "# Function to estimate GAD-7 ratings based on selected_posts\n",
        "def estimate_gad7_scores(post, keywords):\n",
        "    scores = []\n",
        "    post_lower = post.lower()\n",
        "    for key, phrases in keywords.items():\n",
        "        score = any(phrase in post_lower for phrase in phrases)\n",
        "        scores.append(int(score))  # Simple binary score for presence of keywords\n",
        "    return scores\n",
        "\n",
        "# Apply the function to generate GAD-7 ratings\n",
        "gad7_scores = [estimate_gad7_scores(post, gad7_keywords) for post in df_all['selected_posts']]\n",
        "X_gad7 = np.array(gad7_scores)\n",
        "\n",
        "# Process the text data (selected_posts)\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
        "X_text = vectorizer.fit_transform(df_all['selected_posts'])\n",
        "\n",
        "# Combine text features with estimated GAD-7 scores\n",
        "X_combined = hstack([X_text, X_gad7])\n",
        "\n",
        "# Set up the target variable based on the presence of 'anxiety' in the diseases list\n",
        "y = df_all['diseases'].apply(lambda diseases: 1 if 'anxiety' in diseases else 0).values\n",
        "\n",
        "# Initialize the 5-fold Stratified cross-validation\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Metrics storage\n",
        "f1_scores = []\n",
        "sensitivity_scores = []\n",
        "specificity_scores = []\n",
        "\n",
        "# Function to calculate specificity\n",
        "def specificity_score(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "# Cross-validation process\n",
        "for train_index, test_index in kf.split(X_combined, y):\n",
        "    X_train, X_test = X_combined.tocsr()[train_index], X_combined.tocsr()[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Train a logistic regression model\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test fold\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate and store metrics\n",
        "    f1_scores.append(f1_score(y_test, y_pred))\n",
        "    sensitivity_scores.append(recall_score(y_test, y_pred))\n",
        "    specificity_scores.append(specificity_score(y_test, y_pred))\n",
        "\n",
        "# Calculate the mean and standard deviation for each metric\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "mean_sensitivity = np.mean(sensitivity_scores)\n",
        "std_sensitivity = np.std(sensitivity_scores)\n",
        "mean_specificity = np.mean(specificity_scores)\n",
        "std_specificity = np.std(specificity_scores)\n",
        "\n",
        "# Print the results\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: Mean = {mean_f1:.3f}, Std = {std_f1:.3f}\")\n",
        "print(f\"Sensitivity: Mean = {mean_sensitivity:.3f}, Std = {std_sensitivity:.3f}\")\n",
        "print(f\"Specificity: Mean = {mean_specificity:.3f}, Std = {std_specificity:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfZOsmqncoKB",
        "outputId": "2e2c6f27-4567-422e-c76e-9a2d85cd8c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores:\n",
            "F1 Score: Mean = 0.431, Std = 0.022\n",
            "Sensitivity: Mean = 0.319, Std = 0.019\n",
            "Specificity: Mean = 0.985, Std = 0.002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, recall_score, confusion_matrix\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Assuming df_all is already defined in your environment\n",
        "# Make sure to convert lists in 'selected_posts' to single strings\n",
        "df_all['selected_posts'] = df_all['selected_posts'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
        "\n",
        "# Define keywords or phrases indicative of each GAD-7 item\n",
        "gad7_keywords = {\n",
        "    \"nervousness\": [\"nervous\", \"anxious\", \"on edge\"],\n",
        "    \"uncontrol\": [\"can't stop\", \"uncontrollable\"],\n",
        "    \"excess\": [\"too much\", \"excessive\", \"all the time\"],\n",
        "    \"relaxation\": [\"can't relax\", \"trouble relaxing\"],\n",
        "    \"restlessness\": [\"restless\", \"can't sit still\"],\n",
        "    \"irritability\": [\"annoyed\", \"irritable\"],\n",
        "    \"fear\": [\"afraid\", \"fearful\", \"something awful\"]\n",
        "}\n",
        "\n",
        "# Function to estimate GAD-7 ratings based on selected_posts\n",
        "def estimate_gad7_scores(post, keywords):\n",
        "    scores = []\n",
        "    post_lower = post.lower()\n",
        "    for key, phrases in keywords.items():\n",
        "        score = any(phrase in post_lower for phrase in phrases)\n",
        "        scores.append(int(score))  # Simple binary score for presence of keywords\n",
        "    return scores\n",
        "\n",
        "# Apply the function to generate GAD-7 ratings\n",
        "gad7_scores = [estimate_gad7_scores(post, gad7_keywords) for post in df_all['selected_posts']]\n",
        "X_gad7 = np.array(gad7_scores)\n",
        "\n",
        "# Process the text data (selected_posts) using CountVectorizer instead of TfidfVectorizer\n",
        "vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n",
        "X_text = vectorizer.fit_transform(df_all['selected_posts'])\n",
        "\n",
        "# Combine text features with estimated GAD-7 scores\n",
        "X_combined = hstack([X_text, X_gad7])\n",
        "\n",
        "# Set up the target variable based on the presence of 'anxiety' in the diseases list\n",
        "y = df_all['diseases'].apply(lambda diseases: 1 if 'anxiety' in diseases else 0).values\n",
        "\n",
        "# Initialize the 5-fold Stratified cross-validation\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Metrics storage\n",
        "f1_scores = []\n",
        "sensitivity_scores = []\n",
        "specificity_scores = []\n",
        "\n",
        "# Function to calculate specificity\n",
        "def specificity_score(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "# Cross-validation process\n",
        "for train_index, test_index in kf.split(X_combined, y):\n",
        "    X_train, X_test = X_combined.tocsr()[train_index], X_combined.tocsr()[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Train a logistic regression model\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test fold\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate and store metrics\n",
        "    f1_scores.append(f1_score(y_test, y_pred))\n",
        "    sensitivity_scores.append(recall_score(y_test, y_pred))\n",
        "    specificity_scores.append(specificity_score(y_test, y_pred))\n",
        "\n",
        "# Calculate the mean and standard deviation for each metric\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "mean_sensitivity = np.mean(sensitivity_scores)\n",
        "std_sensitivity = np.std(sensitivity_scores)\n",
        "mean_specificity = np.mean(specificity_scores)\n",
        "std_specificity = np.std(specificity_scores)\n",
        "\n",
        "# Print the results\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: Mean = {mean_f1:.3f}, Std = {std_f1:.3f}\")\n",
        "print(f\"Sensitivity: Mean = {mean_sensitivity:.3f}, Std = {std_sensitivity:.3f}\")\n",
        "print(f\"Specificity: Mean = {mean_specificity:.3f}, Std = {std_specificity:.3f}\")\n"
      ],
      "metadata": {
        "id": "78XloUXmkQwX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e00631b-55cd-42e5-c8eb-a269879ca7b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores:\n",
            "F1 Score: Mean = 0.409, Std = 0.018\n",
            "Sensitivity: Mean = 0.326, Std = 0.011\n",
            "Specificity: Mean = 0.975, Std = 0.003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ThiS_FE1m5h",
        "outputId": "3259aef9-7cec-4310-ef7a-75b7de1bf1af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2024.2.2)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, recall_score, confusion_matrix\n",
        "from scipy.sparse import hstack\n",
        "import spacy\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Load SpaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Sentiment analyzer\n",
        "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Assuming df_all is already defined in your environment\n",
        "df_all['selected_posts'] = df_all['selected_posts'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
        "\n",
        "gad7_keywords = {\n",
        "    \"nervousness\": [\"nervous\", \"anxious\", \"on edge\"],\n",
        "    \"uncontrol\": [\"can't stop\", \"uncontrollable\"],\n",
        "    \"excess\": [\"too much\", \"excessive\", \"all the time\"],\n",
        "    \"relaxation\": [\"can't relax\", \"trouble relaxing\"],\n",
        "    \"restlessness\": [\"restless\", \"can't sit still\"],\n",
        "    \"irritability\": [\"annoyed\", \"irritable\"],\n",
        "    \"fear\": [\"afraid\", \"fearful\", \"something awful\"]\n",
        "}\n",
        "\n",
        "# Define enhanced keyword extraction and sentiment analysis\n",
        "def enhanced_score_estimation(post):\n",
        "    doc = nlp(post)\n",
        "    sentiment_score = sentiment_analyzer.polarity_scores(post)['compound']\n",
        "\n",
        "    scores = []\n",
        "    for key, phrases in gad7_keywords.items():\n",
        "        # Consider both occurrence and sentiment\n",
        "        phrase_score = sum(token.lemma_ in phrases for token in doc)\n",
        "        scores.append(phrase_score * sentiment_score)  # Weight by sentiment\n",
        "    return scores\n",
        "\n",
        "# Apply the function to generate GAD-7 ratings\n",
        "gad7_scores = [enhanced_score_estimation(post) for post in df_all['selected_posts']]\n",
        "X_gad7 = np.array(gad7_scores)\n",
        "\n",
        "# Process the text data\n",
        "vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n",
        "X_text = vectorizer.fit_transform(df_all['selected_posts'])\n",
        "\n",
        "# Combine features\n",
        "X_combined = hstack([X_text, X_gad7])\n",
        "y = (df_all['diseases'].apply(lambda diseases: 1 if 'anxiety' in diseases else 0)).values\n",
        "\n",
        "# Cross-validation setup\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Metrics\n",
        "f1_scores = []\n",
        "sensitivity_scores = []\n",
        "specificity_scores = []\n",
        "\n",
        "# Cross-validation process\n",
        "for train_index, test_index in kf.split(X_combined, y):\n",
        "    X_train, X_test = X_combined[train_index], X_combined[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    f1_scores.append(f1_score(y_test, y_pred))\n",
        "    sensitivity_scores.append(recall_score(y_test, y_pred))\n",
        "    specificity_scores.append(specificity_score(y_test, y_pred))\n",
        "\n",
        "# Output results\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "mean_sensitivity = np.mean(sensitivity_scores)\n",
        "std_sensitivity = np.std(sensitivity_scores)\n",
        "mean_specificity = np.mean(specificity_scores)\n",
        "std_specificity = np.std(specificity_scores)\n",
        "\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: Mean = {mean_f1:.3f}, Std = {std_f1:.3f}\")\n",
        "print(f\"Sensitivity: Mean = {mean_sensitivity:.3f}, Std = {std_sensitivity:.3f}\")\n",
        "print(f\"Specificity: Mean = {mean_specificity:.3f}, Std = {std_specificity:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "UvGE6Nct1Dr-",
        "outputId": "8b4c9c2f-5234-4cbc-ed91-464d4a08b3c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'coo_matrix' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-0f68c5c51706>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Cross-validation process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_combined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_combined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_combined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'coo_matrix' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZsKVTviw1sCh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}