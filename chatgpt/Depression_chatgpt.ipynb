{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Stw1qCGucBi6"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/Colab_Notebooks/MDDdataset/symptom_sum_top16/train.pkl', 'rb') as f:\n",
        "      raw_train_data = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/Colab_Notebooks/MDDdataset/symptom_sum_top16/test.pkl', 'rb') as f:\n",
        "      raw_test_data = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/Colab_Notebooks/MDDdataset/symptom_sum_top16/val.pkl', 'rb') as f:\n",
        "      raw_val_data = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlUX_uV02GbA",
        "outputId": "369cd943-1504-4109-d555-fe5f0f4c0094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_data=pd.DataFrame(raw_train_data)\n",
        "test_data=pd.DataFrame(raw_test_data)\n",
        "val_data=pd.DataFrame(raw_val_data)"
      ],
      "metadata": {
        "id": "pzo16-RWcJfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = pd.concat([train_data, val_data], axis=0)\n",
        "df_all = pd.concat([df_all, test_data], axis=0)"
      ],
      "metadata": {
        "id": "XMoTuGXlcKkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.utils import resample\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Define keyword mapping\n",
        "keyword_mapping = {\n",
        "    \"Feeling sad or down in the dumps\": [\"feeling sad\", \"down in the dumps\", \"depressed\", \"unhappy\"],\n",
        "    \"Feeling unhappy or blue\": [\"feeling unhappy\", \"feeling blue\", \"downhearted\", \"gloomy\"],\n",
        "    \"Crying spells or tearfulness\": [\"crying spells\", \"tearful\", \"tears\", \"weepy\"],\n",
        "    \"Feeling discouraged\": [\"feeling discouraged\", \"disheartened\", \"hopeless\", \"pessimistic\"],\n",
        "    \"Feeling hopeless\": [\"feeling hopeless\", \"despair\", \"no hope\", \"futile\"],\n",
        "    \"Low self-esteem\": [\"low self-esteem\", \"poor self-image\", \"self-loathing\", \"insecure\"],\n",
        "    \"Feeling worthless or inadequate\": [\"feeling worthless\", \"inadequate\", \"insignificant\", \"valueless\"],\n",
        "    \"Guilt or shame\": [\"guilt\", \"shame\", \"remorseful\", \"guilty\"],\n",
        "    \"Criticizing yourself or blaming others\": [\"self-criticism\", \"self-blame\", \"blaming others\", \"fault-finding\"],\n",
        "    \"Difficulty making decisions\": [\"indecisive\", \"difficulty deciding\", \"hesitant\", \"uncertain\"],\n",
        "    \"Loss of interest in family, friends or colleagues\": [\"loss of interest\", \"disinterested\", \"apathetic\", \"detached\"],\n",
        "    \"Loneliness\": [\"loneliness\", \"isolated\", \"alone\", \"solitary\"],\n",
        "    \"Spending less time with family or friends\": [\"less social\", \"avoiding people\", \"withdrawn\", \"reclusive\"],\n",
        "    \"Loss of motivation\": [\"loss of motivation\", \"unmotivated\", \"lack of drive\", \"apathetic\"],\n",
        "    \"Loss of interest in work or other activities\": [\"loss of interest in work\", \"disinterest in activities\", \"bored\", \"unengaged\"],\n",
        "    \"Avoiding work or other activities\": [\"avoiding work\", \"shirking responsibilities\", \"neglecting tasks\", \"procrastinating\"],\n",
        "    \"Loss of pleasure or satisfaction in life\": [\"anhedonia\", \"loss of pleasure\", \"joyless\", \"dissatisfaction\"],\n",
        "    \"Feeling tired\": [\"feeling tired\", \"fatigued\", \"exhausted\", \"worn out\"],\n",
        "    \"Difficulty sleeping or sleeping too much\": [\"insomnia\", \"oversleeping\", \"sleep disturbances\", \"restless sleep\"],\n",
        "    \"Decreased or increased appetite\": [\"poor appetite\", \"overeating\", \"loss of appetite\", \"binge eating\"],\n",
        "    \"Loss of interest in sex\": [\"loss of libido\", \"disinterest in sex\", \"sexual apathy\", \"low sex drive\"],\n",
        "    \"Worrying about your health\": [\"health anxiety\", \"hypochondria\", \"preoccupied with health\", \"health worries\"],\n",
        "    \"Do you have any suicidal thoughts?\": [\"suicidal thoughts\", \"thinking about suicide\", \"suicidal ideation\", \"self-harm thoughts\"],\n",
        "    \"Would you like to end your life?\": [\"wanting to end life\", \"wishing for death\", \"suicidal desire\", \"thoughts of dying\"],\n",
        "    \"Do you have a plan for harming yourself?\": [\"suicide plan\", \"self-harm plan\", \"planning suicide\", \"intent to self-harm\"]\n",
        "}\n",
        "\n",
        "# Function to score a post based on keywords\n",
        "def score_post(post, keyword_mapping):\n",
        "    scores = {}\n",
        "    for item, keywords in keyword_mapping.items():\n",
        "        scores[item] = any(keyword in post for keyword in keywords)\n",
        "    return scores\n",
        "\n",
        "# Load the dataset\n",
        "train_df = train_data\n",
        "test_df = test_data\n",
        "\n",
        "# Join the list of posts into a single string and convert to lowercase\n",
        "train_df['joined_posts'] = train_df['selected_posts'].apply(lambda posts: ' '.join(posts).lower())\n",
        "test_df['joined_posts'] = test_df['selected_posts'].apply(lambda posts: ' '.join(posts).lower())\n",
        "\n",
        "# Apply the scoring function to each post in the training and test data\n",
        "train_df['scores'] = train_df['joined_posts'].apply(lambda post: score_post(post, keyword_mapping))\n",
        "test_df['scores'] = test_df['joined_posts'].apply(lambda post: score_post(post, keyword_mapping))\n",
        "\n",
        "# Convert scores to DataFrame\n",
        "train_scores_df = pd.DataFrame(train_df['scores'].tolist())\n",
        "test_scores_df = pd.DataFrame(test_df['scores'].tolist())\n",
        "\n",
        "# Create binary labels from the 'diseases' column\n",
        "train_df['depression_label'] = train_df['diseases'].apply(lambda diseases: 1 if 'depression' in diseases else 0)\n",
        "test_df['depression_label'] = test_df['diseases'].apply(lambda diseases: 1 if 'depression' in diseases else 0)\n",
        "\n",
        "# Check the distribution of labels\n",
        "print(train_df['depression_label'].value_counts())\n",
        "print(test_df['depression_label'].value_counts())\n",
        "\n",
        "# Extract text features using CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_text = vectorizer.fit_transform(train_df['joined_posts'])\n",
        "X_test_text = vectorizer.transform(test_df['joined_posts'])\n",
        "\n",
        "# Combine text features with the keyword-based scores\n",
        "X_train = hstack([X_train_text, train_scores_df])\n",
        "X_test = hstack([X_test_text, test_scores_df])\n",
        "y_train = train_df['depression_label']\n",
        "y_test = test_df['depression_label']\n",
        "\n",
        "# Train model on the entire training set\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Parameters for bootstrap\n",
        "n_iterations = 100  # Number of bootstrap samples\n",
        "\n",
        "n_size = X_test.shape[0]  # Use the size of the test set for each sample\n",
        "\n",
        "# Arrays to store metrics\n",
        "f1_scores = []\n",
        "sensitivities = []\n",
        "specificities = []\n",
        "\n",
        "# Function to calculate sensitivity and specificity\n",
        "def sensitivity_specificity(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    sensitivity = cm[1, 1] / (cm[1, 1] + cm[1, 0])\n",
        "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "    return sensitivity, specificity\n",
        "\n",
        "# Bootstrap sampling on the fixed test set\n",
        "for i in range(n_iterations):\n",
        "    # Prepare a bootstrap sample from the test set\n",
        "    X_sample, y_sample = resample(X_test, y_test, n_samples=n_size, replace=True)\n",
        "\n",
        "    # Predict on the bootstrap sample\n",
        "    y_pred = model.predict(X_sample)\n",
        "\n",
        "    # Compute metrics\n",
        "    f1 = f1_score(y_sample, y_pred)\n",
        "    sensitivity, specificity = sensitivity_specificity(y_sample, y_pred)\n",
        "\n",
        "    # Append to results\n",
        "    f1_scores.append(f1)\n",
        "    sensitivities.append(sensitivity)\n",
        "    specificities.append(specificity)\n",
        "\n",
        "# Calculate mean and standard deviation for each metric\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "mean_sensitivity = np.mean(sensitivities)\n",
        "std_sensitivity = np.std(sensitivities)\n",
        "mean_specificity = np.mean(specificities)\n",
        "std_specificity = np.std(specificities)\n",
        "\n",
        "# Print results in the specified format\n",
        "print(f\"F1 Score: {mean_f1:.3f}±{std_f1:.3f}\")\n",
        "print(f\"Sensitivity: {mean_sensitivity:.3f}±{std_sensitivity:.3f}\")\n",
        "print(f\"Specificity: {mean_specificity:.3f}±{std_specificity:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4CSWLHlJxXP",
        "outputId": "c73ac435-5e9c-498a-ad21-1ec25b7cdda0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.493±0.024\n",
            "Sensitivity: 0.434±0.026\n",
            "Specificity: 0.954±0.004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "# Define keyword mapping\n",
        "keyword_mapping = {\n",
        "    \"Feeling sad or down in the dumps\": [\"feeling sad\", \"down in the dumps\", \"depressed\", \"unhappy\"],\n",
        "    \"Feeling unhappy or blue\": [\"feeling unhappy\", \"feeling blue\", \"downhearted\", \"gloomy\"],\n",
        "    \"Crying spells or tearfulness\": [\"crying spells\", \"tearful\", \"tears\", \"weepy\"],\n",
        "    \"Feeling discouraged\": [\"feeling discouraged\", \"disheartened\", \"hopeless\", \"pessimistic\"],\n",
        "    \"Feeling hopeless\": [\"feeling hopeless\", \"despair\", \"no hope\", \"futile\"],\n",
        "    \"Low self-esteem\": [\"low self-esteem\", \"poor self-image\", \"self-loathing\", \"insecure\"],\n",
        "    \"Feeling worthless or inadequate\": [\"feeling worthless\", \"inadequate\", \"insignificant\", \"valueless\"],\n",
        "    \"Guilt or shame\": [\"guilt\", \"shame\", \"remorseful\", \"guilty\"],\n",
        "    \"Criticizing yourself or blaming others\": [\"self-criticism\", \"self-blame\", \"blaming others\", \"fault-finding\"],\n",
        "    \"Difficulty making decisions\": [\"indecisive\", \"difficulty deciding\", \"hesitant\", \"uncertain\"],\n",
        "    \"Loss of interest in family, friends or colleagues\": [\"loss of interest\", \"disinterested\", \"apathetic\", \"detached\"],\n",
        "    \"Loneliness\": [\"loneliness\", \"isolated\", \"alone\", \"solitary\"],\n",
        "    \"Spending less time with family or friends\": [\"less social\", \"avoiding people\", \"withdrawn\", \"reclusive\"],\n",
        "    \"Loss of motivation\": [\"loss of motivation\", \"unmotivated\", \"lack of drive\", \"apathetic\"],\n",
        "    \"Loss of interest in work or other activities\": [\"loss of interest in work\", \"disinterest in activities\", \"bored\", \"unengaged\"],\n",
        "    \"Avoiding work or other activities\": [\"avoiding work\", \"shirking responsibilities\", \"neglecting tasks\", \"procrastinating\"],\n",
        "    \"Loss of pleasure or satisfaction in life\": [\"anhedonia\", \"loss of pleasure\", \"joyless\", \"dissatisfaction\"],\n",
        "    \"Feeling tired\": [\"feeling tired\", \"fatigued\", \"exhausted\", \"worn out\"],\n",
        "    \"Difficulty sleeping or sleeping too much\": [\"insomnia\", \"oversleeping\", \"sleep disturbances\", \"restless sleep\"],\n",
        "    \"Decreased or increased appetite\": [\"poor appetite\", \"overeating\", \"loss of appetite\", \"binge eating\"],\n",
        "    \"Loss of interest in sex\": [\"loss of libido\", \"disinterest in sex\", \"sexual apathy\", \"low sex drive\"],\n",
        "    \"Worrying about your health\": [\"health anxiety\", \"hypochondria\", \"preoccupied with health\", \"health worries\"],\n",
        "    \"Do you have any suicidal thoughts?\": [\"suicidal thoughts\", \"thinking about suicide\", \"suicidal ideation\", \"self-harm thoughts\"],\n",
        "    \"Would you like to end your life?\": [\"wanting to end life\", \"wishing for death\", \"suicidal desire\", \"thoughts of dying\"],\n",
        "    \"Do you have a plan for harming yourself?\": [\"suicide plan\", \"self-harm plan\", \"planning suicide\", \"intent to self-harm\"]\n",
        "}\n",
        "\n",
        "# Function to score a post based on keywords\n",
        "def score_post(post, keyword_mapping):\n",
        "    scores = {}\n",
        "    for item, keywords in keyword_mapping.items():\n",
        "        scores[item] = any(keyword in post for keyword in keywords)\n",
        "    return scores\n",
        "\n",
        "# Load the dataset\n",
        "train_df = df_all\n",
        "\n",
        "# Join the list of posts into a single string and convert to lowercase\n",
        "train_df['joined_posts'] = train_df['selected_posts'].apply(lambda posts: ' '.join(posts).lower())\n",
        "\n",
        "# Apply the scoring function to each post in the dataset\n",
        "train_df['scores'] = train_df['joined_posts'].apply(lambda post: score_post(post, keyword_mapping))\n",
        "\n",
        "# Convert scores to DataFrame\n",
        "train_scores_df = pd.DataFrame(train_df['scores'].tolist())\n",
        "\n",
        "# Create binary labels from the 'diseases' column\n",
        "train_df['depression_label'] = train_df['diseases'].apply(lambda diseases: 1 if 'depression' in diseases else 0)\n",
        "\n",
        "# Check the distribution of labels\n",
        "print(train_df['depression_label'].value_counts())\n",
        "\n",
        "# Extract text features using CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X_text = vectorizer.fit_transform(train_df['joined_posts'])\n",
        "\n",
        "# Combine text features with the keyword-based scores\n",
        "X = hstack([X_text, csr_matrix(train_scores_df)])\n",
        "X = csr_matrix(X)  # Ensure the combined matrix is in CSR format\n",
        "y = train_df['depression_label']\n",
        "\n",
        "# Perform stratified 5-fold cross-validation\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Arrays to store metrics\n",
        "f1_scores = []\n",
        "sensitivities = []\n",
        "specificities = []\n",
        "\n",
        "# Function to calculate sensitivity and specificity\n",
        "def sensitivity_specificity(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    sensitivity = cm[1, 1] / (cm[1, 1] + cm[1, 0])\n",
        "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "    return sensitivity, specificity\n",
        "\n",
        "# Cross-validation loop\n",
        "for train_index, test_index in kf.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Train model on the training set\n",
        "    model = LogisticRegression(solver='liblinear')\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Compute metrics\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    sensitivity, specificity = sensitivity_specificity(y_test, y_pred)\n",
        "\n",
        "    # Append to results\n",
        "    f1_scores.append(f1)\n",
        "    sensitivities.append(sensitivity)\n",
        "    specificities.append(specificity)\n",
        "\n",
        "# Calculate mean and standard deviation for each metric\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "mean_sensitivity = np.mean(sensitivities)\n",
        "std_sensitivity = np.std(sensitivities)\n",
        "mean_specificity = np.mean(specificities)\n",
        "std_specificity = np.std(specificities)\n",
        "\n",
        "# Print results in the specified format\n",
        "print(f\"F1 Score: {mean_f1:.3f}±{std_f1:.3f}\")\n",
        "print(f\"Sensitivity: {mean_sensitivity:.3f}±{std_sensitivity:.3f}\")\n",
        "print(f\"Specificity: {mean_specificity:.3f}±{std_specificity:.3f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TcCHwNAlk4xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "514c7c01-e5c2-4a50-ce75-f5cc4f0de12e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depression_label\n",
            "0    23500\n",
            "1     3105\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.499±0.021\n",
            "Sensitivity: 0.420±0.024\n",
            "Specificity: 0.965±0.006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fctNkC2oWxYy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}