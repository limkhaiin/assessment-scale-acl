{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_N7u7boY_XH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "project_folder = \"/content/drive/MyDrive/Colab_Notebooks/MDDdataset/symptom_sum_top16/claude_results\"\n",
        "\n",
        "def create_and_set_working_directory(project_folder):\n",
        "  # check if your project folder exists. if not, it will be created.\n",
        "  if os.path.isdir(project_folder) == False:\n",
        "    os.mkdir(project_folder)\n",
        "    print(project_folder + ' did not exist but was created.')\n",
        "\n",
        "  # change the OS to use your project folder as the working directory\n",
        "  os.chdir(project_folder)\n",
        "create_and_set_working_directory(project_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n20tz58_ZFQd"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/Colab_Notebooks/MDDdataset/symptom_sum_top16/test.pkl', 'rb') as f:\n",
        "      raw_test_data = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/Colab_Notebooks/MDDdataset/symptom_sum_top16/val.pkl', 'rb') as f:\n",
        "      raw_val_data = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/Colab_Notebooks/MDDdataset/symptom_sum_top16/train.pkl', 'rb') as f:\n",
        "      raw_train_data = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3OVCbVbZpRW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train_data=pd.DataFrame(raw_train_data)\n",
        "test_data_diseases=pd.DataFrame(raw_test_data)\n",
        "val_data=pd.DataFrame(raw_val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMayQihObMqo"
      },
      "outputs": [],
      "source": [
        "test_data=test_data_diseases[['id', 'selected_posts']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwvhfeesZzD7"
      },
      "outputs": [],
      "source": [
        "all_data = pd.concat([train_data, val_data], axis=0, ignore_index=True)\n",
        "all_data = pd.concat([all_data, test_data_diseases], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stVmQKDAokwN"
      },
      "outputs": [],
      "source": [
        "y_all=[]\n",
        "for row in all_data['diseases']:\n",
        "  if 'bipolar' in row:\n",
        "    y_all.append(1)\n",
        "  else:\n",
        "    y_all.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mV4Rsj2yaHHF"
      },
      "outputs": [],
      "source": [
        "y_true_train=[]\n",
        "for row in train_data['diseases']:\n",
        "  if 'schizophrenia' in row:\n",
        "    y_true_train.append(1)\n",
        "  else:\n",
        "    y_true_train.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMon-sUFaJI-"
      },
      "outputs": [],
      "source": [
        "y_true_test=[]\n",
        "for row in test_data_diseases['diseases']:\n",
        "  if 'schizophrenia' in row:\n",
        "    y_true_test.append(1)\n",
        "  else:\n",
        "    y_true_test.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJwqGjO5PKuf",
        "outputId": "ed35a298-3ffc-463a-d858-4a2619cecb58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "345\n"
          ]
        }
      ],
      "source": [
        "count=0\n",
        "for row in y_all:\n",
        "  if row==1:\n",
        "    count+=1\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAdGR7tpk-kx",
        "outputId": "8f3e17ca-cd25-4567-d9e1-80baf8b6b038"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17\n"
          ]
        }
      ],
      "source": [
        "count=0\n",
        "for row in y_true_test:\n",
        "  if row==1:\n",
        "    count+=1\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwurG4BHaKXI"
      },
      "source": [
        "### **Anxiety**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xEi1xiH5qGp"
      },
      "outputs": [],
      "source": [
        "gad7_keywords = [\n",
        "    [\"nervous\", \"anxious\", \"on edge\"],\n",
        "    [\"can't stop worrying\", \"can't control worrying\"],\n",
        "    [\"worrying too much\", \"excessive worrying\"],\n",
        "    [\"trouble relaxing\"],\n",
        "    [\"restless\", \"hard to sit still\"],\n",
        "    [\"easily annoyed\", \"irritable\"],\n",
        "    [\"feeling afraid\", \"something awful might happen\"]\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5uqsjzhsqN8",
        "outputId": "4b51c867-4daa-4916-88b9-ee201c18418b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Standard Deviation of F1 Scores (Bootstrap): 0.03334622718882116\n",
            "Standard Deviation of Recall Scores (Bootstrap): 0.03191497895545451\n",
            "Standard Deviation of Precision Scores (Bootstrap): 0.004052742653125046\n",
            "f1_score 0.464846516933431\n",
            "recall 0.35069747676628277\n",
            "precision 0.9579844326095862\n",
            "std_f1_score 0.03334622718882116\n",
            "std_recall_score 0.03191497895545451\n",
            "std_precision_score 0.004052742653125046\n"
          ]
        }
      ],
      "source": [
        "#baseline+test\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "\n",
        "!python -m nltk.downloader stopwords\n",
        "# Load the trained model and vectorizer\n",
        "model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "vectorizer = TfidfVectorizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Load and preprocess the training data\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Train the model\n",
        "X = vectorizer.fit_transform(all_data['selected_posts'])\n",
        "y = y_true_train\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "# Perform cross-validation\n",
        "model.fit(X_train, y_train)\n",
        "predictions=model.predict(X_test)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 100\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    sensitivity = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    specificity = recall_score(np.logical_not(true_labels) , np.logical_not(bootstrap_preds))\n",
        "    return f1, sensitivity, specificity\n",
        "\n",
        "# Generate bootstrap samples and calculate scores\n",
        "bootstrap_scores_list = [bootstrap_scores(y_test, predictions) for _ in range(num_bootstraps)]\n",
        "\n",
        "# Calculate standard deviation of scores\n",
        "f1_scores, recall_scores, precision_scores = zip(*bootstrap_scores_list)\n",
        "std_f1_score = np.std(f1_scores)\n",
        "std_recall_score = np.std(recall_scores)\n",
        "std_precision_score = np.std(precision_scores)\n",
        "\n",
        "# Print results\n",
        "print(\"Standard Deviation of F1 Scores (Bootstrap):\", std_f1_score)\n",
        "print(\"Standard Deviation of Recall Scores (Bootstrap):\", std_recall_score)\n",
        "print(\"Standard Deviation of Precision Scores (Bootstrap):\", std_precision_score)\n",
        "\n",
        "# Print results\n",
        "print(\"f1_score\", np.mean(f1_scores))\n",
        "print(\"recall\", np.mean(recall_scores))\n",
        "print(\"precision\", np.mean(precision_scores))\n",
        "print(\"std_f1_score\", std_f1_score)\n",
        "print(\"std_recall_score\", std_recall_score)\n",
        "print(\"std_precision_score\", std_precision_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Kb5Pq_l8XjG"
      },
      "outputs": [],
      "source": [
        "with open('anxiety-test-simple.npy', 'wb') as f:\n",
        "    np.save(f, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQrEP-j2bRuC",
        "outputId": "52c5adc6-b6c0-4a20-c66a-1894fa298458"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Cross-validation scores:\n",
            "F1 Score: 0.3917 ± 0.0607\n",
            "Sensitivity: 0.3024 ± 0.0481\n",
            "Specificity: 0.9689 ± 0.0539\n"
          ]
        }
      ],
      "source": [
        "#baseline+all\n",
        "!pip install -U scikit-learn\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "# Load the trained model and vectorizer\n",
        "model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "vectorizer = TfidfVectorizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Function to calculate specificity\n",
        "def specificity_score(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    sensitivity = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    specificity = recall_score(np.logical_not(true_labels) , np.logical_not(bootstrap_preds))\n",
        "    return f1, sensitivity, specificity\n",
        "\n",
        "\n",
        "# Load and preprocess the training data\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Preprocess the text data\n",
        "X = vectorizer.fit_transform(all_data['selected_posts'])\n",
        "y = y_true_train\n",
        "\n",
        "\n",
        "# Define the scoring metrics\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(specificity_score)\n",
        "}\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(model, X, y, cv=5, scoring=scoring, return_estimator=True, return_indices=True)\n",
        "\n",
        "# Calculate the mean and standard deviation of the scores\n",
        "f1_mean = np.mean(cv_scores['test_f1'])\n",
        "f1_std = np.std(cv_scores['test_f1'])\n",
        "sensitivity_mean = np.mean(cv_scores['test_sensitivity'])\n",
        "sensitivity_std = np.std(cv_scores['test_sensitivity'])\n",
        "specificity_mean = np.mean(cv_scores['test_specificity'])\n",
        "specificity_std = np.std(cv_scores['test_specificity'])\n",
        "'''\n",
        "# Get the predictions for each fold\n",
        "fold_predictions_cross = []\n",
        "for estimator, test_index in zip(cv_scores['estimator'], cv_scores['indices']['test']):\n",
        "    print(test_index)\n",
        "    X_test_fold = X_combined.tocsr()[test_index]\n",
        "    y_test_fold = y[test_index]\n",
        "    y_pred_fold = estimator.predict(X_test_fold)\n",
        "    fold_predictions_cross.append((y_test_fold, y_pred_fold))\n",
        "'''\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} ± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} ± {specificity_std:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CF93RKt8UKR"
      },
      "outputs": [],
      "source": [
        "with open('anxiety-all-simple.npy', 'wb') as f:\n",
        "    np.save(f, cv_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQghyYlHBoaa",
        "outputId": "1be0526b-2d44-4004-d1e8-eb5721bc1333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Cross-validation scores:\n",
            "F1 Score: 0.3917 ± 0.0607\n",
            "Sensitivity: 0.3024 ± 0.0481\n",
            "Specificity: 0.9689 ± 0.0539\n"
          ]
        }
      ],
      "source": [
        "#simple+all\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "# Load the trained model and vectorizer\n",
        "model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "vectorizer = TfidfVectorizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Function to calculate specificity\n",
        "def specificity_score(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    sensitivity = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    specificity = recall_score(np.logical_not(true_labels) , np.logical_not(bootstrap_preds))\n",
        "    return f1, sensitivity, specificity\n",
        "\n",
        "\n",
        "# Load and preprocess the training data\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Preprocess the text data\n",
        "X = vectorizer.fit_transform(all_data['selected_posts'])\n",
        "y = y_true_train\n",
        "\n",
        "\n",
        "# Define the scoring metrics\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(specificity_score)\n",
        "}\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(model, X, y, cv=5, scoring=scoring, return_estimator=True, return_indices=True)\n",
        "\n",
        "# Calculate the mean and standard deviation of the scores\n",
        "f1_mean = np.mean(cv_scores['test_f1'])\n",
        "f1_std = np.std(cv_scores['test_f1'])\n",
        "sensitivity_mean = np.mean(cv_scores['test_sensitivity'])\n",
        "sensitivity_std = np.std(cv_scores['test_sensitivity'])\n",
        "specificity_mean = np.mean(cv_scores['test_specificity'])\n",
        "specificity_std = np.std(cv_scores['test_specificity'])\n",
        "'''\n",
        "# Get the predictions for each fold\n",
        "fold_predictions_cross = []\n",
        "for estimator, test_index in zip(cv_scores['estimator'], cv_scores['indices']['test']):\n",
        "    print(test_index)\n",
        "    X_test_fold = X_combined.tocsr()[test_index]\n",
        "    y_test_fold = y[test_index]\n",
        "    y_pred_fold = estimator.predict(X_test_fold)\n",
        "    fold_predictions_cross.append((y_test_fold, y_pred_fold))\n",
        "'''\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} ± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} ± {specificity_std:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Voz9CoFDaUz",
        "outputId": "4aaee6ef-fdf2-4489-a084-68e8317c9d36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['random_forest_classifier.joblib']"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(rf_classifier, \"random_forest_classifier.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_csi775LHWO"
      },
      "outputs": [],
      "source": [
        "prediction_test=rf_classifier.predict(X_combined[100:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4baDZKgWMSZT",
        "outputId": "d5e94c4e-f16d-412f-9140-89d42c360895"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.019801980198019802"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1_score(y_true_train[100:200], prediction_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohQSc4C5G7TQ"
      },
      "outputs": [],
      "source": [
        "with open('y_test_best.npy', 'wb') as f:\n",
        "    np.save(f, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCeDJiTWDx1r"
      },
      "outputs": [],
      "source": [
        "from scipy import sparse\n",
        "\n",
        "#Save\n",
        "sparse.save_npz('X_test_best.npz', X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXh8SlcPcgML",
        "outputId": "019a56e0-28cf-4414-bbaf-190d33b0c6cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Standard Deviation of F1 Scores (Bootstrap): 0.002473165079025267\n",
            "Standard Deviation of Recall Scores (Bootstrap): 0.0008199850904003263\n",
            "Standard Deviation of Precision Scores (Bootstrap): 0.0043503644081515054\n",
            "f1_score 0.9565598673397717\n",
            "recall 0.9983846546463291\n",
            "precision 0.9181078524116326\n",
            "std_f1_score 0.002473165079025267\n",
            "std_recall_score 0.0008199850904003263\n",
            "std_precision_score 0.0043503644081515054\n"
          ]
        }
      ],
      "source": [
        "#!pip install -U scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "def generate_ratings(user_posts, assessment_items, vectorizer, stop_words):\n",
        "    user_ratings = []\n",
        "    for item in assessment_items:\n",
        "        count = sum(item.lower() in post.lower() for post in user_posts)\n",
        "        rating = min(count, 3)  # Limit the rating to a maximum of 3 based on GAD-7 scale\n",
        "        user_ratings.append(rating)\n",
        "    return user_ratings\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: [preprocess_text(post, stop_words) for post in x])\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X_text = all_data['selected_posts']\n",
        "y = y_true_train\n",
        "\n",
        "# Convert the target variable to numerical labels\n",
        "y = pd.factorize(y)[0]\n",
        "\n",
        "# Convert text to Bag-of-Words representation\n",
        "vectorizer = CountVectorizer()\n",
        "X_text_vec = vectorizer.fit_transform([' '.join(posts) for posts in X_text])\n",
        "\n",
        "# Generate ratings for each data point\n",
        "X_ratings = []\n",
        "for _, row in all_data.iterrows():\n",
        "    user_posts = row['selected_posts']\n",
        "    user_ratings = generate_ratings(user_posts, gad7_items, vectorizer, stop_words)\n",
        "    X_ratings.append(user_ratings)\n",
        "\n",
        "# Convert ratings to a numpy array\n",
        "X_ratings = np.array(X_ratings)\n",
        "\n",
        "# Determine the presence of anxiety based on a threshold of 5\n",
        "anxiety_threshold = 5\n",
        "X_anxiety = np.where(np.sum(X_ratings, axis=1) >= anxiety_threshold, 1, 0)\n",
        "\n",
        "# Combine text features and anxiety presence\n",
        "X_combined = hstack([X_text_vec, X_anxiety.reshape(-1, 1)])\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "X_combined = X_combined.tocsr()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "predictions = rf_classifier.predict(X_test)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 100\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "  indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "  bootstrap_true_labels = np.take(true_labels, indices)\n",
        "  bootstrap_preds = np.take(preds, indices)\n",
        "  f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "  recall = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "  precision = precision_score(bootstrap_true_labels, bootstrap_preds)\n",
        "  return f1, recall, precision\n",
        "\n",
        "# Generate bootstrap samples and calculate scores\n",
        "bootstrap_scores_list = [bootstrap_scores(y_test, predictions) for _ in range(num_bootstraps)]\n",
        "\n",
        "# Calculate standard deviation of scores\n",
        "f1_scores, recall_scores, precision_scores = zip(*bootstrap_scores_list)\n",
        "std_f1_score = np.std(f1_scores)\n",
        "std_recall_score = np.std(recall_scores)\n",
        "std_precision_score = np.std(precision_scores)\n",
        "\n",
        "# Print results\n",
        "print(\"Standard Deviation of F1 Scores (Bootstrap):\", std_f1_score)\n",
        "print(\"Standard Deviation of Recall Scores (Bootstrap):\", std_recall_score)\n",
        "print(\"Standard Deviation of Precision Scores (Bootstrap):\", std_precision_score)\n",
        "# Print results\n",
        "print(\"f1_score\", np.mean(f1_scores))\n",
        "print(\"recall\", np.mean(recall_scores))\n",
        "print(\"precision\", np.mean(precision_scores))\n",
        "print(\"std_f1_score\", std_f1_score)\n",
        "print(\"std_recall_score\", std_recall_score)\n",
        "print(\"std_precision_score\", std_precision_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcqlfMYMJvRl"
      },
      "outputs": [],
      "source": [
        "with open('path/to/file', 'wb') as f:\n",
        "    cPickle.dump(rf, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmxE-KiV_Hoo"
      },
      "outputs": [],
      "source": [
        "predictions=np.load('anxiety-test-assessment.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "id": "I18NCC-Jz_E-",
        "outputId": "fd4e86a5-a8ec-40c3-b1d0-fa70b3f81b81"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'lower'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-0788652b6bbf>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mX_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgad7_keywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgad7_keywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mX_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Combine text features and rating features using sparse matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4628\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4629\u001b[0m         \"\"\"\n\u001b[0;32m-> 4630\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4632\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1077\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-0788652b6bbf>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mX_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgad7_keywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgad7_keywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mX_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Combine text features and rating features using sparse matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
          ]
        }
      ],
      "source": [
        "#assessment+ test\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score, confusion_matrix\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.sparse import hstack\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "def generate_ratings(user_posts, assessment_items, vectorizer, stop_words):\n",
        "    user_ratings = []\n",
        "    for item in assessment_items:\n",
        "        if any(item.lower() in post.lower() for post in user_posts):\n",
        "            user_ratings.append(1)  # Item is present in user's posts\n",
        "        else:\n",
        "            user_ratings.append(0)  # Item is not present in user's posts\n",
        "    return user_ratings\n",
        "\n",
        "# Function to calculate specificity\n",
        "def specificity_score(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: [preprocess_text(post, stop_words) for post in x])\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X_text = all_data['selected_posts']\n",
        "y = y_true_train\n",
        "\n",
        "# Convert the target variable to numerical labels\n",
        "y = pd.factorize(y)[0]\n",
        "\n",
        "# Load and preprocess the training data\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Preprocess the text data\n",
        "X_text = vectorizer.fit_transform(all_data['selected_posts'])\n",
        "\n",
        "X_ratings = np.zeros((len(all_data), len(gad7_keywords)))\n",
        "for i, item in enumerate(gad7_keywords):\n",
        "    X_ratings[:, i] = all_data['selected_posts'].apply(lambda x: item.lower() in x.lower()).astype(int)\n",
        "\n",
        "# Combine text features and rating features using sparse matrices\n",
        "X_combined = hstack((X_text, X_ratings))\n",
        "\n",
        "y = y_true_train\n",
        "\n",
        "# Define the scoring metrics\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score, average='weighted'),\n",
        "    'sensitivity': make_scorer(recall_score, average='weighted'),\n",
        "    'specificity': make_scorer(specificity_score)\n",
        "}\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "predictions=model.predict(X_test)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 100\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    sensitivity = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    specificity = recall_score(np.logical_not(true_labels) , np.logical_not(bootstrap_preds))\n",
        "    return f1, sensitivity, specificity\n",
        "\n",
        "# Generate bootstrap samples and calculate scores\n",
        "bootstrap_scores_list = [bootstrap_scores(y_test, predictions) for _ in range(num_bootstraps)]\n",
        "\n",
        "# Calculate standard deviation of scores\n",
        "f1_scores, sensitivity_scores, specificity_scores = zip(*bootstrap_scores_list)\n",
        "std_f1_score = np.std(f1_scores)\n",
        "std_sensitivity_score= np.std(sensitivity_scores)\n",
        "std_specificity_score = np.std(specificity_scores)\n",
        "\n",
        "# Print results\n",
        "print(\"Standard Deviation of F1 Scores (Bootstrap):\", std_f1_score)\n",
        "print(\"Standard Deviation of sensitivity Scores (Bootstrap):\", std_sensitivity_score)\n",
        "print(\"Standard Deviation of specificity Scores (Bootstrap):\", std_specificity_score)\n",
        "\n",
        "# Print results\n",
        "print(\"f1_score\", np.mean(f1_scores))\n",
        "print(\"sensitivity\", np.mean(sensitivity_scores))\n",
        "print(\"specificity\", np.mean(specificity_scores))\n",
        "print(\"std_f1_score\", std_f1_score)\n",
        "print(\"std_sensitivity_score\", std_sensitivity_score)\n",
        "print(\"std_specificity_score\", std_specificity_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nSKy4Xk8CgA"
      },
      "outputs": [],
      "source": [
        "with open('anxiety-test-assessment.npy', 'rb') as f:\n",
        "    predictions=np.load('anxiety-test-assessment.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRyAMFU46G0W",
        "outputId": "4536e3d1-adf0-44a3-cad5-b30c2a06e13d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation scores:\n",
            "F1 Score: 0.3873 ± 0.0611\n",
            "Sensitivity: 0.2983 ± 0.0495\n",
            "Specificity: 0.9688 ± 0.0543\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_validate\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.sparse import hstack\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the trained model and vectorizer\n",
        "model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "vectorizer = TfidfVectorizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds, average='weighted')\n",
        "    recall = recall_score(bootstrap_true_labels, bootstrap_preds, average='weighted')\n",
        "    precision = precision_score(bootstrap_true_labels, bootstrap_preds, average='weighted')\n",
        "    return f1, recall, precision\n",
        "\n",
        "# Function to calculate specificity\n",
        "def specificity_score(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "# Load and preprocess the training data\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Preprocess the text data\n",
        "X_text = vectorizer.fit_transform(all_data['selected_posts'])\n",
        "X_ratings = np.zeros((len(all_data), len(gad7_keywords)))\n",
        "for i, item in enumerate(gad7_keywords):\n",
        "    X_ratings[:, i] = all_data['selected_posts'].apply(lambda x: any(keyword.lower() in x.lower() for keyword in item)).astype(int)\n",
        "\n",
        "# Combine text features and rating features using sparse matrices\n",
        "X_combined = hstack((X_text, X_ratings))\n",
        "y = y_all\n",
        "\n",
        "# Define the scoring metrics\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(specificity_score)\n",
        "}\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(model, X_combined, y, cv=5, scoring=scoring, return_estimator=True)\n",
        "\n",
        "# Calculate the mean and standard deviation of the scores\n",
        "f1_mean = np.mean(cv_scores['test_f1'])\n",
        "f1_std = np.std(cv_scores['test_f1'])\n",
        "sensitivity_mean = np.mean(cv_scores['test_sensitivity'])\n",
        "sensitivity_std = np.std(cv_scores['test_sensitivity'])\n",
        "specificity_mean = np.mean(cv_scores['test_specificity'])\n",
        "specificity_std = np.std(cv_scores['test_specificity'])\n",
        "\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} ± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} ± {specificity_std:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k11aa11L8P4S"
      },
      "outputs": [],
      "source": [
        "with open('anxiety-all-assessment.npy', 'wb') as f:\n",
        "    np.save(f, cv_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHQj2fwZ7wB8"
      },
      "source": [
        "### **Bipolar**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSUQK0JOA8w1"
      },
      "outputs": [],
      "source": [
        "# Define the bipolar disorder assessment items from the checklist\n",
        "bipolar_items = [\n",
        "    \"Feeling low, irritable or appearing tearful\",\n",
        "    \"Reduced interest or pleasure in most activities\",\n",
        "    \"Marked increase or decrease in appetite, or significant weight loss\",\n",
        "    \"Difficulties sleeping and waking\",\n",
        "    \"Increased agitation or lethargy\",\n",
        "    \"Fatigue\",\n",
        "    \"Feeling worthless or guilty\",\n",
        "    \"Less able to make decisions or concentrate\",\n",
        "    \"Recurrent thoughts of death or suicide\",\n",
        "    \"Inflated self-esteem and grandiosity\",\n",
        "    \"Decreased need for sleep\",\n",
        "    \"More talkative than usual\",\n",
        "    \"Flight of ideas or racing thoughts\",\n",
        "    \"Distractibility\",\n",
        "    \"Increase in goal-directed activity\",\n",
        "    \"Excessive involvement in risky activities (e.g. overspending, sexual indiscretions, foolish investments)\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7tRxex7pRDQ"
      },
      "outputs": [],
      "source": [
        "# Define the bipolar disorder assessment keywords\n",
        "bipolar_keywords = [\n",
        "    \"low mood\",\n",
        "    \"irritability\",\n",
        "    \"tearfulness\",\n",
        "    \"loss of interest\",\n",
        "    \"reduced pleasure\",\n",
        "    \"appetite changes\",\n",
        "    \"weight changes\",\n",
        "    \"sleep disturbances\",\n",
        "    \"agitation\",\n",
        "    \"lethargy\",\n",
        "    \"fatigue\",\n",
        "    \"worthlessness\",\n",
        "    \"guilt\",\n",
        "    \"indecisiveness\",\n",
        "    \"concentration difficulties\",\n",
        "    \"suicidal thoughts\",\n",
        "    \"inflated self-esteem\",\n",
        "    \"grandiosity\",\n",
        "    \"decreased need for sleep\",\n",
        "    \"talkativeness\",\n",
        "    \"flight of ideas\",\n",
        "    \"racing thoughts\",\n",
        "    \"distractibility\",\n",
        "    \"goal-directed activity\",\n",
        "    \"risky behavior\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXTD62O8mzxR",
        "outputId": "01b5901d-71ec-4da0-9b35-c5eee674a40c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "<ipython-input-14-55aad6a57cac>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_data['selected_posts'] = test_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.4860±0.0000\n",
            "Recall Score: 0.3333±0.0000\n",
            "Specificity Score: 0.9976±0.0000\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "# Load the trained model and vectorizer\n",
        "model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "vectorizer = TfidfVectorizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Load and preprocess the training data\n",
        "train_data['selected_posts'] = train_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "test_data['selected_posts'] = test_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Preprocess the text data\n",
        "X_train = vectorizer.fit_transform(train_data['selected_posts'])\n",
        "X_test = vectorizer.transform(test_data['selected_posts'])\n",
        "y_train = y_true_train  # Assuming 'anxiety' is the column containing the anxiety labels in the training data\n",
        "y_test = y_true_test  # Assuming 'anxiety' is the column containing the anxiety labels in the test data\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 100\n",
        "\n",
        "# Function to calculate F1, recall, and specificity scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    tn, fp, fn, tp = confusion_matrix(true_labels, preds).ravel()\n",
        "    f1 = f1_score(true_labels, preds)\n",
        "    recall = recall_score(true_labels, preds)\n",
        "    specificity = tn / (tn + fp)\n",
        "    return f1, recall, specificity\n",
        "\n",
        "# Generate bootstrap samples and calculate scores\n",
        "bootstrap_scores_list = [bootstrap_scores(y_test, y_pred) for _ in range(num_bootstraps)]\n",
        "\n",
        "# Calculate mean and standard deviation of scores\n",
        "f1_scores, recall_scores, specificity_scores = zip(*bootstrap_scores_list)\n",
        "mean_f1_score = np.mean(f1_scores)\n",
        "mean_recall_score = np.mean(recall_scores)\n",
        "mean_specificity_score = np.mean(specificity_scores)\n",
        "std_f1_score = np.std(f1_scores)\n",
        "std_recall_score = np.std(recall_scores)\n",
        "std_specificity_score = np.std(specificity_scores)\n",
        "\n",
        "# Print results in the desired format\n",
        "print(f\"F1 Score: {mean_f1_score:.4f}±{std_f1_score:.4f}\")\n",
        "print(f\"Recall Score: {mean_recall_score:.4f}±{std_recall_score:.4f}\")\n",
        "print(f\"Specificity Score: {mean_specificity_score:.4f}±{std_specificity_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rXCzAOn_bVp"
      },
      "outputs": [],
      "source": [
        "with open('bipolar-test-simple.npy', 'wb') as f:\n",
        "    np.save(f, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaJcHldK_XRZ",
        "outputId": "18c73180-0cd1-4b0e-9ee3-9aa16bdec69f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#baseline+all\n",
        "\n",
        "!pip install -U scikit-learn\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Load and preprocess the data\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Load the trained model and vectorizer\n",
        "model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "vectorizer = TfidfVectorizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Preprocess the text data\n",
        "X_text = vectorizer.fit_transform(all_data['selected_posts'])\n",
        "\n",
        "# Generate assessment scale features\n",
        "def generate_assessment_features(user_posts, assessment_items):\n",
        "    user_features = []\n",
        "    for item in assessment_items:\n",
        "        count = sum(item.lower() in post.lower() for post in user_posts)\n",
        "        user_features.append(count)\n",
        "    return user_features\n",
        "\n",
        "assessment_features = all_data['selected_posts'].apply(lambda x: generate_assessment_features(x, bipolar_keywords))\n",
        "X_assessment = pd.DataFrame(assessment_features.tolist())\n",
        "\n",
        "# Combine text features and assessment features\n",
        "X = pd.concat([pd.DataFrame(X_text.toarray()), X_assessment], axis=1)\n",
        "\n",
        "y = y_all\n",
        "\n",
        "# Define the scoring metrics\n",
        "def specificity_score(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(specificity_score)\n",
        "}\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(model, X, y, cv=5, scoring=scoring, return_estimator=True, return_train_score=True)\n",
        "\n",
        "# Calculate the mean and standard deviation of the scores\n",
        "f1_mean = np.mean(cv_scores['test_f1'])\n",
        "f1_std = np.std(cv_scores['test_f1'])\n",
        "sensitivity_mean = np.mean(cv_scores['test_sensitivity'])\n",
        "sensitivity_std = np.std(cv_scores['test_sensitivity'])\n",
        "specificity_mean = np.mean(cv_scores['test_specificity'])\n",
        "specificity_std = np.std(cv_scores['test_specificity'])\n",
        "\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} ± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} ± {specificity_std:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryji-lLz_fmO"
      },
      "outputs": [],
      "source": [
        "with open('bipolar-all-simple.npy', 'wb') as f:\n",
        "    np.save(f, cv_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV1iGlXwuXFO",
        "outputId": "631f3069-85f4-4c94-dcd4-b3d898682288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.0246 ± 0.0185\n",
            "Sensitivity: 0.0126 ± 0.0095\n",
            "Specificity: 1.0000 ± 0.0000\n"
          ]
        }
      ],
      "source": [
        "#!pip install -U scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, confusion_matrix\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "def generate_ratings(user_posts, assessment_items, vectorizer, stop_words):\n",
        "    user_ratings = []\n",
        "    for item in assessment_items:\n",
        "        count = sum(item.lower() in post.lower() for post in user_posts)\n",
        "        rating = min(count, 1)  # Limit the rating to a maximum of 1 based on the checklist scale\n",
        "        user_ratings.append(rating)\n",
        "    return user_ratings\n",
        "\n",
        "# Preprocess the text data for train and test sets\n",
        "stop_words = set(stopwords.words('english'))\n",
        "train_data['selected_posts'] = train_data['selected_posts'].apply(lambda x: [preprocess_text(post, stop_words) for post in x])\n",
        "test_data['selected_posts'] = test_data['selected_posts'].apply(lambda x: [preprocess_text(post, stop_words) for post in x])\n",
        "\n",
        "# Convert text to Bag-of-Words representation for train and test sets\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_text_vec = vectorizer.fit_transform([' '.join(posts) for posts in train_data['selected_posts']])\n",
        "X_test_text_vec = vectorizer.transform([' '.join(posts) for posts in test_data['selected_posts']])\n",
        "\n",
        "# Generate ratings for each data point in train and test sets\n",
        "X_train_ratings = []\n",
        "for _, row in train_data.iterrows():\n",
        "    user_posts = row['selected_posts']\n",
        "    user_ratings = generate_ratings(user_posts, bipolar_keywords, vectorizer, stop_words)\n",
        "    X_train_ratings.append(user_ratings)\n",
        "\n",
        "X_test_ratings = []\n",
        "for _, row in test_data.iterrows():\n",
        "    user_posts = row['selected_posts']\n",
        "    user_ratings = generate_ratings(user_posts, bipolar_keywords, vectorizer, stop_words)\n",
        "    X_test_ratings.append(user_ratings)\n",
        "\n",
        "# Convert ratings to numpy arrays for train and test sets\n",
        "X_train_ratings = np.array(X_train_ratings)\n",
        "X_test_ratings = np.array(X_test_ratings)\n",
        "\n",
        "# Determine the presence of bipolar disorder based on the criteria from the checklist for train and test sets\n",
        "manic_threshold = 3\n",
        "depressive_threshold = 5\n",
        "X_train_bipolar = np.where((np.sum(X_train_ratings[:, 9:], axis=1) >= manic_threshold) & (np.sum(X_train_ratings[:, :9], axis=1) >= depressive_threshold), 1, 0)\n",
        "X_test_bipolar = np.where((np.sum(X_test_ratings[:, 9:], axis=1) >= manic_threshold) & (np.sum(X_test_ratings[:, :9], axis=1) >= depressive_threshold), 1, 0)\n",
        "\n",
        "# Combine text features and bipolar presence for train and test sets\n",
        "X_train_combined = hstack([X_train_text_vec, X_train_bipolar.reshape(-1, 1)])\n",
        "X_test_combined = hstack([X_test_text_vec, X_test_bipolar.reshape(-1, 1)])\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "X_train_combined = X_train_combined.tocsr()\n",
        "X_test_combined = X_test_combined.tocsr()\n",
        "\n",
        "# Train the model\n",
        "rf_classifier.fit(X_train_combined, y_true_train)\n",
        "predictions = rf_classifier.predict(X_test_combined)\n",
        "\n",
        "# ... (rest of the code remains the same)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 100\n",
        "\n",
        "# Function to calculate F1, sensitivity, and specificity scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    sensitivity = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    tn, fp, fn, tp = confusion_matrix(bootstrap_true_labels, bootstrap_preds).ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "    return f1, sensitivity, specificity\n",
        "\n",
        "# Generate bootstrap samples and calculate scores\n",
        "bootstrap_scores_list = [bootstrap_scores(y_true_test, predictions) for _ in range(num_bootstraps)]\n",
        "\n",
        "# Calculate standard deviation of scores\n",
        "f1_scores, sensitivity_scores, specificity_scores = zip(*bootstrap_scores_list)\n",
        "std_f1_score = np.std(f1_scores)\n",
        "std_sensitivity_score = np.std(sensitivity_scores)\n",
        "std_specificity_score = np.std(specificity_scores)\n",
        "\n",
        "# Print results\n",
        "print(f\"F1 Score: {np.mean(f1_scores):.4f} ± {std_f1_score:.4f}\")\n",
        "print(f\"Sensitivity: {np.mean(sensitivity_scores):.4f} ± {std_sensitivity_score:.4f}\")\n",
        "print(f\"Specificity: {np.mean(specificity_scores):.4f} ± {std_specificity_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jCZi94YEO54"
      },
      "outputs": [],
      "source": [
        "with open('bipolar-simple-assessment.npy', 'wb') as f:\n",
        "    np.save(f, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDF2twHHA4Tw",
        "outputId": "786656f4-07fd-4c7b-d8cc-b712c1d46e70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation scores:\n",
            "F1 Score: 0.0348 ± 0.0422\n",
            "Sensitivity: 0.0198 ± 0.0255\n",
            "Specificity: 0.9986 ± 0.0028\n"
          ]
        }
      ],
      "source": [
        "!pip install -U scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, confusion_matrix\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "def generate_ratings(user_posts, assessment_items, vectorizer, stop_words):\n",
        "    user_ratings = []\n",
        "    for item in assessment_items:\n",
        "        count = sum(item.lower() in post.lower() for post in user_posts)\n",
        "        rating = min(count, 1)  # Limit the rating to a maximum of 1 based on the checklist scale\n",
        "        user_ratings.append(rating)\n",
        "    return user_ratings\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: [preprocess_text(post, stop_words) for post in x])\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X_text = all_data['selected_posts']\n",
        "y = y_all  # Assuming 'bipolar' is the column containing the bipolar disorder labels\n",
        "\n",
        "# Convert the target variable to numerical labels\n",
        "y = pd.factorize(y)[0]\n",
        "\n",
        "# Convert text to Bag-of-Words representation\n",
        "vectorizer = CountVectorizer()\n",
        "X_text_vec = vectorizer.fit_transform([' '.join(posts) for posts in X_text])\n",
        "\n",
        "# Generate ratings for each data point\n",
        "X_ratings = []\n",
        "for _, row in all_data.iterrows():\n",
        "    user_posts = row['selected_posts']\n",
        "    user_ratings = generate_ratings(user_posts, bipolar_keywords, vectorizer, stop_words)\n",
        "    X_ratings.append(user_ratings)\n",
        "\n",
        "# Convert ratings to a numpy array\n",
        "X_ratings = np.array(X_ratings)\n",
        "\n",
        "# Combine text features and rating features\n",
        "X_combined = hstack([X_text_vec, X_ratings])\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Define the scoring metrics\n",
        "def specificity_score(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(specificity_score)\n",
        "}\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(rf_classifier, X_combined, y, cv=5, scoring=scoring, return_estimator=True, return_train_score=True)\n",
        "\n",
        "# Calculate the mean and standard deviation of the scores\n",
        "f1_mean = np.mean(cv_scores['test_f1'])\n",
        "f1_std = np.std(cv_scores['test_f1'])\n",
        "sensitivity_mean = np.mean(cv_scores['test_sensitivity'])\n",
        "sensitivity_std = np.std(cv_scores['test_sensitivity'])\n",
        "specificity_mean = np.mean(cv_scores['test_specificity'])\n",
        "specificity_std = np.std(cv_scores['test_specificity'])\n",
        "\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} ± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} ± {specificity_std:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05u56O94ELnx"
      },
      "outputs": [],
      "source": [
        "with open('bipolar-all-assessment.npy', 'wb') as f:\n",
        "    np.save(f, cv_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S22JRVfREZ0E"
      },
      "source": [
        "### **ocd**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfIlq9lAIGWg"
      },
      "outputs": [],
      "source": [
        "ocd_items = [\n",
        "    \"Having to check and double-check what you do.\",\n",
        "    \"Having to do things very slowly to insure correctness.\",\n",
        "    \"Your mind going blank\",\n",
        "    \"Trouble remembering things.\",\n",
        "    \"Difficulty making decisions.\",\n",
        "    \"Trouble concentrating.\",\n",
        "    \"Worried about sloppiness or carelessness.\",\n",
        "    \"Feeling blocked in getting things done.\",\n",
        "    \"Having to repeat the same actions, i.e., counting, washing.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CkFpJ7fN-fl"
      },
      "outputs": [],
      "source": [
        "ocd_items = [\n",
        "    \"check\",\n",
        "    \"double-check\",\n",
        "    \"slowly\",\n",
        "    \"correctness\",\n",
        "    \"mind going blank\",\n",
        "    \"remembering\",\n",
        "    \"trouble remembering\",\n",
        "    \"difficulty making decisions\",\n",
        "    \"trouble concentrating\",\n",
        "    \"worried\",\n",
        "    \"sloppiness\",\n",
        "    \"carelessness\",\n",
        "    \"blocked\",\n",
        "    \"getting things done\",\n",
        "    \"repeat\",\n",
        "    \"same actions\",\n",
        "    \"counting\",\n",
        "    \"washing\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEzXJX1eEb3m",
        "outputId": "544da9e2-aa7b-42e4-ddfb-dc6643ddfb4f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "<ipython-input-29-55aad6a57cac>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_data['selected_posts'] = test_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.1957±0.0000\n",
            "Recall Score: 0.1125±0.0000\n",
            "Specificity Score: 0.9988±0.0000\n"
          ]
        }
      ],
      "source": [
        "#test-baseline\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "# Load the trained model and vectorizer\n",
        "model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "vectorizer = TfidfVectorizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Load and preprocess the training data\n",
        "train_data['selected_posts'] = train_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "test_data['selected_posts'] = test_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Preprocess the text data\n",
        "X_train = vectorizer.fit_transform(train_data['selected_posts'])\n",
        "X_test = vectorizer.transform(test_data['selected_posts'])\n",
        "y_train = y_true_train  # Assuming 'anxiety' is the column containing the anxiety labels in the training data\n",
        "y_test = y_true_test  # Assuming 'anxiety' is the column containing the anxiety labels in the test data\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 100\n",
        "\n",
        "# Function to calculate F1, recall, and specificity scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    tn, fp, fn, tp = confusion_matrix(true_labels, preds).ravel()\n",
        "    f1 = f1_score(true_labels, preds)\n",
        "    recall = recall_score(true_labels, preds)\n",
        "    specificity = tn / (tn + fp)\n",
        "    return f1, recall, specificity\n",
        "\n",
        "# Generate bootstrap samples and calculate scores\n",
        "bootstrap_scores_list = [bootstrap_scores(y_test, y_pred) for _ in range(num_bootstraps)]\n",
        "\n",
        "# Calculate mean and standard deviation of scores\n",
        "f1_scores, recall_scores, specificity_scores = zip(*bootstrap_scores_list)\n",
        "mean_f1_score = np.mean(f1_scores)\n",
        "mean_recall_score = np.mean(recall_scores)\n",
        "mean_specificity_score = np.mean(specificity_scores)\n",
        "std_f1_score = np.std(f1_scores)\n",
        "std_recall_score = np.std(recall_scores)\n",
        "std_specificity_score = np.std(specificity_scores)\n",
        "\n",
        "# Print results in the desired format\n",
        "print(f\"F1 Score: {mean_f1_score:.4f}±{std_f1_score:.4f}\")\n",
        "print(f\"Recall Score: {mean_recall_score:.4f}±{std_recall_score:.4f}\")\n",
        "print(f\"Specificity Score: {mean_specificity_score:.4f}±{std_specificity_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HzU6wapiX_T"
      },
      "outputs": [],
      "source": [
        "with open('ocd-test-simple.npy', 'wb') as f:\n",
        "    np.save(f, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdsFLbb6EqFL",
        "outputId": "f32ff492-a97e-45b1-eca0-9746124e26b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Cross-validation scores:\n",
            "F1 Score: 0.1660 ± 0.0370\n",
            "Sensitivity: 0.1182 ± 0.0520\n",
            "Specificity: 0.9900 ± 0.0197\n"
          ]
        }
      ],
      "source": [
        "#baseline+all\n",
        "!pip install -U scikit-learn\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "\n",
        "# Load the trained model and vectorizer\n",
        "model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "vectorizer = TfidfVectorizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    recall = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    precision = precision_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    return f1, recall, precision\n",
        "\n",
        "\n",
        "# Load and preprocess the training data\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Preprocess the text data\n",
        "X = vectorizer.fit_transform(all_data['selected_posts'])\n",
        "y = y_all\n",
        "\n",
        "\n",
        "# Define the scoring metrics\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(specificity_score)\n",
        "}\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(model, X, y, cv=5, scoring=scoring, return_estimator=True, return_indices=True)\n",
        "\n",
        "# Calculate the mean and standard deviation of the scores\n",
        "f1_mean = np.mean(cv_scores['test_f1'])\n",
        "f1_std = np.std(cv_scores['test_f1'])\n",
        "sensitivity_mean = np.mean(cv_scores['test_sensitivity'])\n",
        "sensitivity_std = np.std(cv_scores['test_sensitivity'])\n",
        "specificity_mean = np.mean(cv_scores['test_specificity'])\n",
        "specificity_std = np.std(cv_scores['test_specificity'])\n",
        "'''\n",
        "# Get the predictions for each fold\n",
        "fold_predictions_cross = []\n",
        "for estimator, test_index in zip(cv_scores['estimator'], cv_scores['indices']['test']):\n",
        "    print(test_index)\n",
        "    X_test_fold = X_combined.tocsr()[test_index]\n",
        "    y_test_fold = y[test_index]\n",
        "    y_pred_fold = estimator.predict(X_test_fold)\n",
        "    fold_predictions_cross.append((y_test_fold, y_pred_fold))\n",
        "'''\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} ± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} ± {specificity_std:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BL_TRMoNiegM"
      },
      "outputs": [],
      "source": [
        "with open('ocd-all-simple.npy', 'wb') as f:\n",
        "    np.save(f, cv_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8i_d5g9Hs4G",
        "outputId": "d4fffead-a14e-447a-d7ac-d19089a63c11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.0000 ± 0.0000\n",
            "Sensitivity: 0.0000 ± 0.0000\n",
            "Specificity: 0.0000 ± 0.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "#test-assessment\n",
        "#!pip install -U scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "def generate_ratings(user_posts, assessment_items, vectorizer, stop_words):\n",
        "    user_ratings = []\n",
        "    for item in assessment_items:\n",
        "        count = sum(item.lower() in post.lower() for post in user_posts)\n",
        "        rating = min(count, 4)  # Limit the rating to a maximum of 4 based on the checklist scale\n",
        "        user_ratings.append(rating)\n",
        "    return user_ratings\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: [preprocess_text(post, stop_words) for post in x])\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X_text = all_data['selected_posts']\n",
        "y = y_true_train\n",
        "\n",
        "# Convert the target variable to numerical labels\n",
        "y = pd.factorize(y)[0]\n",
        "\n",
        "# Convert text to Bag-of-Words representation\n",
        "vectorizer = CountVectorizer()\n",
        "X_text_vec = vectorizer.fit_transform([' '.join(posts) for posts in X_text])\n",
        "\n",
        "# Generate ratings for each data point\n",
        "X_ratings = []\n",
        "for _, row in all_data.iterrows():\n",
        "    user_posts = row['selected_posts']\n",
        "    user_ratings = generate_ratings(user_posts, ocd_items, vectorizer, stop_words)\n",
        "    X_ratings.append(user_ratings)\n",
        "\n",
        "# Convert ratings to a numpy array\n",
        "X_ratings = np.array(X_ratings)\n",
        "\n",
        "# Determine the presence of OCD based on the criteria from the checklist\n",
        "obsessive_threshold = 10\n",
        "compulsive_threshold = 10\n",
        "X_ocd = np.where((np.sum(X_ratings[:, :5], axis=1) >= obsessive_threshold) & (np.sum(X_ratings[:, 5:], axis=1) >= compulsive_threshold), 1, 0)\n",
        "\n",
        "# Combine text features and OCD presence\n",
        "X_combined = hstack([X_text_vec, X_ocd.reshape(-1, 1)])\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "X_combined = X_combined.tocsr()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "predictions = rf_classifier.predict(X_test)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 100\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    recall = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    precision = precision_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    return f1, recall, precision\n",
        "\n",
        "# Generate bootstrap samples and calculate scores\n",
        "bootstrap_scores_list = [bootstrap_scores(y_test, predictions) for _ in range(num_bootstraps)]\n",
        "\n",
        "# Calculate standard deviation of scores\n",
        "f1_scores, recall_scores, precision_scores = zip(*bootstrap_scores_list)\n",
        "std_f1_score = np.std(f1_scores)\n",
        "std_recall_score = np.std(recall_scores)\n",
        "std_precision_score = np.std(precision_scores)\n",
        "\n",
        "# Print results\n",
        "print(f\"F1 Score: {np.mean(f1_scores):.4f} ± {std_f1_score:.4f}\")\n",
        "print(f\"Sensitivity: {np.mean(recall_scores):.4f} ± {std_recall_score:.4f}\")\n",
        "print(f\"Specificity: {np.mean(precision_scores):.4f} ± {std_precision_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npxUQT5CkD5T"
      },
      "outputs": [],
      "source": [
        "with open('ocd-test-assessment.npy', 'wb') as f:\n",
        "    np.save(f, cv_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4an1DaYwILL5",
        "outputId": "13be6b3f-4186-4c2e-f93f-9dd8364ec7a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "Successfully installed scikit-learn-1.4.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation scores:\n",
            "F1 Score: 0.0000 ± 0.0000\n",
            "Sensitivity: 0.0000 ± 0.0000\n",
            "Specificity: 0.0000 ± 0.0000\n"
          ]
        }
      ],
      "source": [
        "#all-assessment\n",
        "!pip install -U scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "def generate_ratings(user_posts, assessment_items, vectorizer, stop_words):\n",
        "    user_ratings = []\n",
        "    for item in assessment_items:\n",
        "        count = sum(item.lower() in post.lower() for post in user_posts)\n",
        "        rating = min(count, 4)  # Limit the rating to a maximum of 4 based on the checklist scale\n",
        "        user_ratings.append(rating)\n",
        "    return user_ratings\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: [preprocess_text(post, stop_words) for post in x])\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X_text = all_data['selected_posts']\n",
        "y = y_true_train  # Assuming 'ocd' is the column containing the OCD labels\n",
        "\n",
        "# Convert the target variable to numerical labels\n",
        "y = pd.factorize(y)[0]\n",
        "\n",
        "# Convert text to Bag-of-Words representation\n",
        "vectorizer = CountVectorizer()\n",
        "X_text_vec = vectorizer.fit_transform([' '.join(posts) for posts in X_text])\n",
        "'''\n",
        "# Generate ratings for each data point\n",
        "X_ratings = []\n",
        "for _, row in all_data.iterrows():\n",
        "    user_posts = row['selected_posts']\n",
        "    user_ratings = generate_ratings(user_posts, ocd_items, vectorizer, stop_words)\n",
        "    X_ratings.append(user_ratings)\n",
        "\n",
        "# Convert ratings to a numpy array\n",
        "X_ratings = np.array(X_ratings)\n",
        "\n",
        "# Determine the presence of OCD based on the criteria from the checklist\n",
        "obsessive_threshold = 10\n",
        "compulsive_threshold = 10\n",
        "X_ocd = np.where((np.sum(X_ratings[:, :5], axis=1) >= obsessive_threshold) & (np.sum(X_ratings[:, 5:], axis=1) >= compulsive_threshold), 1, 0)\n",
        "\n",
        "# Combine text features and OCD presence\n",
        "X_combined = hstack([X_text_vec, X_ocd.reshape(-1, 1)])\n",
        "'''\n",
        "# Train the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Define the scoring metrics\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(lambda y_true, y_pred: precision_score(y_true, y_pred))\n",
        "}\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(rf_classifier, X_text_vec, y, cv=5, scoring=scoring, return_estimator=True, return_train_score=True)\n",
        "\n",
        "# Calculate the mean and standard deviation of the scores\n",
        "f1_mean = np.mean(cv_scores['test_f1'])\n",
        "f1_std = np.std(cv_scores['test_f1'])\n",
        "sensitivity_mean = np.mean(cv_scores['test_sensitivity'])\n",
        "sensitivity_std = np.std(cv_scores['test_sensitivity'])\n",
        "specificity_mean = np.mean(cv_scores['test_specificity'])\n",
        "specificity_std = np.std(cv_scores['test_specificity'])\n",
        "\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} ± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} ± {specificity_std:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IK_Pr633kGpy"
      },
      "outputs": [],
      "source": [
        "with open('ocd-all-assessment.npy', 'wb') as f:\n",
        "    np.save(f, cv_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drbt-vGnkIYh"
      },
      "source": [
        "### **Ptsd**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwxCxs2qWdRz",
        "outputId": "b600a171-2539-4e6d-c265-9a2d62aecba9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "<ipython-input-108-55aad6a57cac>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_data['selected_posts'] = test_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.0000±0.0000\n",
            "Recall Score: 0.0000±0.0000\n",
            "Specificity Score: 1.0000±0.0000\n"
          ]
        }
      ],
      "source": [
        "#baseline+test\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "# Load the trained model and vectorizer\n",
        "model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "vectorizer = TfidfVectorizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Load and preprocess the training data\n",
        "train_data['selected_posts'] = train_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "test_data['selected_posts'] = test_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Preprocess the text data\n",
        "X_train = vectorizer.fit_transform(train_data['selected_posts'])\n",
        "X_test = vectorizer.transform(test_data['selected_posts'])\n",
        "y_train = y_true_train  # Assuming 'anxiety' is the column containing the anxiety labels in the training data\n",
        "y_test = y_true_test  # Assuming 'anxiety' is the column containing the anxiety labels in the test data\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 100\n",
        "\n",
        "# Function to calculate F1, recall, and specificity scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    tn, fp, fn, tp = confusion_matrix(true_labels, preds).ravel()\n",
        "    f1 = f1_score(true_labels, preds)\n",
        "    recall = recall_score(true_labels, preds)\n",
        "    specificity = tn / (tn + fp)\n",
        "    return f1, recall, specificity\n",
        "\n",
        "# Generate bootstrap samples and calculate scores\n",
        "bootstrap_scores_list = [bootstrap_scores(y_test, y_pred) for _ in range(num_bootstraps)]\n",
        "\n",
        "# Calculate mean and standard deviation of scores\n",
        "f1_scores, recall_scores, specificity_scores = zip(*bootstrap_scores_list)\n",
        "mean_f1_score = np.mean(f1_scores)\n",
        "mean_recall_score = np.mean(recall_scores)\n",
        "mean_specificity_score = np.mean(specificity_scores)\n",
        "std_f1_score = np.std(f1_scores)\n",
        "std_recall_score = np.std(recall_scores)\n",
        "std_specificity_score = np.std(specificity_scores)\n",
        "\n",
        "# Print results in the desired format\n",
        "print(f\"F1 Score: {mean_f1_score:.4f}±{std_f1_score:.4f}\")\n",
        "print(f\"Recall Score: {mean_recall_score:.4f}±{std_recall_score:.4f}\")\n",
        "print(f\"Specificity Score: {mean_specificity_score:.4f}±{std_specificity_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6b6IfVWo8uq"
      },
      "outputs": [],
      "source": [
        "with open('ptsd-test-simple.npy', 'wb') as f:\n",
        "    np.save(f, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "eXQ9ynDDkVCp",
        "outputId": "18045e9e-5138-450e-aa3f-f70d0bf928b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-620afa82e793>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Load and preprocess the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Load the trained model and vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4628\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4629\u001b[0m         \"\"\"\n\u001b[0;32m-> 4630\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4632\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1077\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-110-620afa82e793>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Load and preprocess the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Load the trained model and vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-110-620afa82e793>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Load and preprocess the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Load the trained model and vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#baseline+all\n",
        "\n",
        "!pip install -U scikit-learn\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "\n",
        "!python -m nltk.downloader stopwords\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Load and preprocess the data\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Load the trained model and vectorizer\n",
        "model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "vectorizer = TfidfVectorizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Preprocess the text data\n",
        "X = vectorizer.fit_transform(all_data['selected_posts'])\n",
        "y = y_all\n",
        "\n",
        "# Define the scoring metrics\n",
        "def specificity_score(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(specificity_score)\n",
        "}\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(model, X, y, cv=5, scoring=scoring, return_estimator=True, return_train_score=True)\n",
        "\n",
        "# Calculate the mean and standard deviation of the scores\n",
        "f1_mean = np.mean(cv_scores['test_f1'])\n",
        "f1_std = np.std(cv_scores['test_f1'])\n",
        "sensitivity_mean = np.mean(cv_scores['test_sensitivity'])\n",
        "sensitivity_std = np.std(cv_scores['test_sensitivity'])\n",
        "specificity_mean = np.mean(cv_scores['test_specificity'])\n",
        "specificity_std = np.std(cv_scores['test_specificity'])\n",
        "\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} ± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} ± {specificity_std:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KSF6YssmsIH"
      },
      "outputs": [],
      "source": [
        "# assessment+test\n",
        "#!pip install -U scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "def generate_ratings(user_posts, assessment_items, vectorizer, stop_words):\n",
        "    user_ratings = []\n",
        "    for item in assessment_items:\n",
        "        count = sum(item.lower() in post.lower() for post in user_posts)\n",
        "        rating = min(count, 4)  # Limit the rating to a maximum of 4 based on the checklist scale\n",
        "        user_ratings.append(rating)\n",
        "    return user_ratings\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: [preprocess_text(post, stop_words) for post in x])\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X_text = all_data['selected_posts']\n",
        "y = y_true_train\n",
        "\n",
        "# Convert the target variable to numerical labels\n",
        "y = pd.factorize(y)[0]\n",
        "\n",
        "# Convert text to Bag-of-Words representation\n",
        "vectorizer = CountVectorizer()\n",
        "X_text_vec = vectorizer.fit_transform([' '.join(posts) for posts in X_text])\n",
        "\n",
        "# PTSD assessment items\n",
        "ptsd_items = [\n",
        "    'disturbing memories',\n",
        "    'disturbing dreams',\n",
        "    'reliving experience',\n",
        "    'upset by reminders',\n",
        "    'physical reactions to reminders',\n",
        "    'avoiding memories',\n",
        "    'avoiding external reminders',\n",
        "    'trouble remembering',\n",
        "    'negative beliefs',\n",
        "    'blaming',\n",
        "    'negative feelings',\n",
        "    'loss of interest',\n",
        "    'feeling distant',\n",
        "    'trouble experiencing positive feelings',\n",
        "    'irritable behavior',\n",
        "    'taking risks',\n",
        "    'superalert',\n",
        "    'easily startled',\n",
        "    'difficulty concentrating',\n",
        "    'trouble sleeping'\n",
        "]\n",
        "\n",
        "# Generate ratings for each data point\n",
        "X_ratings = []\n",
        "for _, row in all_data.iterrows():\n",
        "    user_posts = row['selected_posts']\n",
        "    user_ratings = generate_ratings(user_posts, ptsd_items, vectorizer, stop_words)\n",
        "    X_ratings.append(user_ratings)\n",
        "\n",
        "# Convert ratings to a numpy array\n",
        "X_ratings = np.array(X_ratings)\n",
        "\n",
        "# Determine the provisional PTSD diagnosis based on the DSM-5 diagnostic rule\n",
        "X_ptsd = np.zeros(len(X_ratings))\n",
        "for i, ratings in enumerate(X_ratings):\n",
        "    b_items = np.sum(ratings[0:5] >= 2) >= 1\n",
        "    c_items = np.sum(ratings[5:7] >= 2) >= 1\n",
        "    d_items = np.sum(ratings[7:14] >= 2) >= 2\n",
        "    e_items = np.sum(ratings[14:20] >= 2) >= 2\n",
        "    if b_items and c_items and d_items and e_items:\n",
        "        X_ptsd[i] = 1\n",
        "\n",
        "# Combine text features and PTSD presence\n",
        "X_combined = hstack([X_text_vec, X_ptsd.reshape(-1, 1)])\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "X_combined = X_combined.tocsr()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "predictions = rf_classifier.predict(X_test)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 100\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    recall = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    precision = precision_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    return f1, recall, precision\n",
        "\n",
        "# Generate bootstrap samples and calculate scores\n",
        "bootstrap_scores_list = [bootstrap_scores(y_test, predictions) for _ in range(num_bootstraps)]\n",
        "\n",
        "# Calculate standard deviation of scores\n",
        "f1_scores, recall_scores, precision_scores = zip(*bootstrap_scores_list)\n",
        "std_f1_score = np.std(f1_scores)\n",
        "std_recall_score = np.std(recall_scores)\n",
        "std_precision_score = np.std(precision_scores)\n",
        "\n",
        "# Print results\n",
        "print(f\"F1 Score: {np.mean(f1_scores):.4f} ± {std_f1_score:.4f}\")\n",
        "print(f\"Sensitivity: {np.mean(recall_scores):.4f} ± {std_recall_score:.4f}\")\n",
        "print(f\"Specificity: {np.mean(precision_scores):.4f} ± {std_precision_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8D7uwLYpnDO"
      },
      "outputs": [],
      "source": [
        "# assessment+all\n",
        "!pip install -U scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "def generate_ratings(user_posts, assessment_items, vectorizer, stop_words):\n",
        "    user_ratings = []\n",
        "    for item in assessment_items:\n",
        "        count = sum(any(keyword.lower() in post.lower() for keyword in item) for post in user_posts)\n",
        "        rating = min(count, 4)  # Limit the rating to a maximum of 4 based on the checklist scale\n",
        "        user_ratings.append(rating)\n",
        "    return user_ratings\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: [preprocess_text(post, stop_words) for post in x])\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X_text = all_data['selected_posts']\n",
        "y = y_true_train  # Assuming 'ptsd' is the column containing the PTSD labels\n",
        "\n",
        "# Convert the target variable to numerical labels\n",
        "y = pd.factorize(y)[0]\n",
        "\n",
        "# Convert text to Bag-of-Words representation\n",
        "vectorizer = CountVectorizer()\n",
        "X_text_vec = vectorizer.fit_transform([' '.join(posts) for posts in X_text])\n",
        "\n",
        "# PTSD assessment items\n",
        "ptsd_items = [\n",
        "    ['intrusive thoughts', 'distressing memories', 'unwanted memories'],\n",
        "    ['nightmares', 'distressing dreams'],\n",
        "    ['flashbacks', 'reliving', 'acting as if it is happening again'],\n",
        "    ['emotional distress', 'upset by reminders', 'psychological distress'],\n",
        "    ['physical reactions', 'physiological reactions', 'heart pounding', 'sweating', 'shaking'],\n",
        "    ['avoidance of thoughts', 'avoiding memories', 'avoiding thinking'],\n",
        "    ['avoidance of reminders', 'avoiding activities', 'avoiding places', 'avoiding people'],\n",
        "    ['inability to remember', 'difficulty remembering', 'trouble remembering'],\n",
        "    ['negative beliefs', 'negative thoughts', 'distorted cognitions'],\n",
        "    ['blaming self', 'blaming others', 'self-blame'],\n",
        "    ['negative emotions', 'fear', 'horror', 'anger', 'guilt', 'shame'],\n",
        "    ['diminished interest', 'loss of interest', 'detachment'],\n",
        "    ['feeling disconnected', 'feeling isolated', 'feeling distant'],\n",
        "    ['difficulty experiencing positive emotions', 'unable to feel happiness', 'unable to feel love'],\n",
        "    ['irritability', 'angry outbursts', 'aggression'],\n",
        "    ['reckless behavior', 'self-destructive behavior', 'taking too many risks'],\n",
        "    ['hypervigilance', 'being on guard', 'heightened awareness'],\n",
        "    ['exaggerated startle response', 'easily startled', 'jumpy'],\n",
        "    ['difficulty concentrating', 'trouble focusing', 'distracted'],\n",
        "    ['sleep disturbance', 'difficulty falling asleep', 'difficulty staying asleep']\n",
        "]\n",
        "\n",
        "# Generate ratings for each data point\n",
        "X_ratings = []\n",
        "for _, row in all_data.iterrows():\n",
        "    user_posts = row['selected_posts']\n",
        "    user_ratings = generate_ratings(user_posts, ptsd_items, vectorizer, stop_words)\n",
        "    X_ratings.append(user_ratings)\n",
        "\n",
        "# Convert ratings to a numpy array\n",
        "X_ratings = np.array(X_ratings)\n",
        "\n",
        "# Determine the provisional PTSD diagnosis based on the DSM-5 diagnostic rule\n",
        "X_ptsd = np.zeros(len(X_ratings))\n",
        "for i, ratings in enumerate(X_ratings):\n",
        "    b_items = np.sum(ratings[0:5] >= 2) >= 1\n",
        "    c_items = np.sum(ratings[5:7] >= 2) >= 1\n",
        "    d_items = np.sum(ratings[7:14] >= 2) >= 2\n",
        "    e_items = np.sum(ratings[14:20] >= 2) >= 2\n",
        "    if b_items and c_items and d_items and e_items:\n",
        "        X_ptsd[i] = 1\n",
        "\n",
        "# Combine text features and PTSD presence\n",
        "X_combined = hstack([X_text_vec, X_ptsd.reshape(-1, 1)])\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Define the scoring metrics\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(lambda y_true, y_pred: precision_score(y_true, y_pred))\n",
        "}\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(rf_classifier, X_combined, y, cv=5, scoring=scoring, return_estimator=True, return_train_score=True)\n",
        "\n",
        "# Calculate the mean and standard deviation of the scores\n",
        "f1_mean = np.mean(cv_scores['test_f1'])\n",
        "f1_std = np.std(cv_scores['test_f1'])\n",
        "sensitivity_mean = np.mean(cv_scores['test_sensitivity'])\n",
        "sensitivity_std = np.std(cv_scores['test_sensitivity'])\n",
        "specificity_mean = np.mean(cv_scores['test_specificity'])\n",
        "specificity_std = np.std(cv_scores['test_specificity'])\n",
        "\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} ± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} ± {specificity_std:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2vblj3qyoff"
      },
      "source": [
        "### **Eating**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuadezlrYJ-o",
        "outputId": "859a9533-4d19-4630-9a1d-fbb6cccf9151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-117-8ff7b7adb78b>:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_data['selected_posts'] = test_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard Deviation of F1 Scores (Bootstrap): 0.0\n",
            "Standard Deviation of Recall Scores (Bootstrap): 0.0\n",
            "Standard Deviation of Precision Scores (Bootstrap): 0.0\n",
            "f1_score 0.0\n",
            "recall 0.0\n",
            "precision 1.0\n",
            "std_f1_score 0.0\n",
            "std_recall_score 0.0\n",
            "std_precision_score 0.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#baseline+test\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "\n",
        "!python -m nltk.downloader stopwords\n",
        "# Load the trained model and vectorizer\n",
        "model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "vectorizer = TfidfVectorizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Load and preprocess the training data\n",
        "train_data['selected_posts'] = train_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "test_data['selected_posts'] = test_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Preprocess the text data\n",
        "X_train = vectorizer.fit_transform(train_data['selected_posts'])\n",
        "X_test = vectorizer.transform(test_data['selected_posts'])\n",
        "y_train = y_true_train  # Assuming 'anxiety' is the column containing the anxiety labels in the training data\n",
        "y_test = y_true_test  # Assuming 'anxiety' is the column containing the anxiety labels in the test data\n",
        "# Perform cross-validation\n",
        "model.fit(X_train, y_train)\n",
        "predictions=model.predict(X_test)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 100\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    sensitivity = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    specificity = recall_score(np.logical_not(true_labels) , np.logical_not(bootstrap_preds))\n",
        "    return f1, sensitivity, specificity\n",
        "\n",
        "# Generate bootstrap samples and calculate scores\n",
        "bootstrap_scores_list = [bootstrap_scores(y_test, predictions) for _ in range(num_bootstraps)]\n",
        "\n",
        "# Calculate standard deviation of scores\n",
        "f1_scores, recall_scores, precision_scores = zip(*bootstrap_scores_list)\n",
        "std_f1_score = np.std(f1_scores)\n",
        "std_recall_score = np.std(recall_scores)\n",
        "std_precision_score = np.std(precision_scores)\n",
        "\n",
        "# Print results\n",
        "print(\"Standard Deviation of F1 Scores (Bootstrap):\", std_f1_score)\n",
        "print(\"Standard Deviation of Recall Scores (Bootstrap):\", std_recall_score)\n",
        "print(\"Standard Deviation of Precision Scores (Bootstrap):\", std_precision_score)\n",
        "\n",
        "# Print results\n",
        "print(\"f1_score\", np.mean(f1_scores))\n",
        "print(\"recall\", np.mean(recall_scores))\n",
        "print(\"precision\", np.mean(precision_scores))\n",
        "print(\"std_f1_score\", std_f1_score)\n",
        "print(\"std_recall_score\", std_recall_score)\n",
        "print(\"std_precision_score\", std_precision_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GQO5ROry9o_",
        "outputId": "aeba6610-4b54-4364-eb0b-86b316e1b730"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.0073 ± 0.0022\n",
            "Sensitivity: 1.0000 ± 0.0000\n",
            "Specificity: 0.0037 ± 0.0011\n"
          ]
        }
      ],
      "source": [
        "#baseline+all\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "# Load and preprocess the training data\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X = all_data['selected_posts']\n",
        "y = y_all# Assuming 'eating_disorder' is the column containing the eating disorder labels\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Create a pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', LinearSVC())\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    recall = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    precision = precision_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    return f1, recall, precision\n",
        "\n",
        "# Generate bootstrap samples and calculate scores\n",
        "bootstrap_scores_list = [bootstrap_scores(y_test, predictions) for _ in range(num_bootstraps)]\n",
        "\n",
        "# Calculate standard deviation of scores\n",
        "f1_scores, recall_scores, precision_scores = zip(*bootstrap_scores_list)\n",
        "std_f1_score = np.std(f1_scores)\n",
        "std_recall_score = np.std(recall_scores)\n",
        "std_precision_score = np.std(precision_scores)\n",
        "\n",
        "# Print results\n",
        "print(f\"F1 Score: {np.mean(f1_scores):.4f} ± {std_f1_score:.4f}\")\n",
        "print(f\"Sensitivity: {np.mean(recall_scores):.4f} ± {std_recall_score:.4f}\")\n",
        "print(f\"Specificity: {np.mean(precision_scores):.4f} ± {std_precision_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRl9v42SXYES"
      },
      "outputs": [],
      "source": [
        "# Eating disorder assessment items\n",
        "eating_disorder_items = [\n",
        "    ['limit food', 'restrict eating', 'influence weight', 'influence shape'],\n",
        "    ['long periods without eating', 'fasting', 'skipping meals'],\n",
        "    ['thinking about food', 'preoccupied with food', 'thinking about calories'],\n",
        "    ['thinking about weight', 'thinking about shape', 'preoccupied with weight', 'preoccupied with shape'],\n",
        "    ['fear of gaining weight', 'afraid of becoming fat'],\n",
        "    ['desire to lose weight', 'want to be thinner'],\n",
        "    ['making yourself sick', 'vomiting', 'taking laxatives'],\n",
        "    ['excessive exercise', 'driven exercise', 'compulsive exercise'],\n",
        "    ['loss of control over eating', 'binge eating'],\n",
        "    ['eating large amounts of food', 'overeating'],\n",
        "    ['weight influences self-evaluation', 'shape influences self-evaluation']\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS3ThfGPsBSC",
        "outputId": "6cfac3e4-bdc9-47db-8900-76f46a1232b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean F1 Score: 0.0000 ± 0.0000\n",
            "Mean Precision: 0.0000 ± 0.0000\n",
            "Mean Recall: 0.0000 ± 0.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# assessment-test\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "def generate_ratings(user_posts, assessment_items, stop_words):\n",
        "    user_ratings = []\n",
        "    for item in assessment_items:\n",
        "        count = sum(any(keyword.lower() in post.lower() for keyword in item) for post in user_posts)\n",
        "        rating = min(count, 4)  # Limit the rating to a maximum of 4 based on the checklist scale\n",
        "        user_ratings.append(rating)\n",
        "    return user_ratings\n",
        "\n",
        "def evaluate_rule_based_method(X_test, y_test, assessment_items, stop_words, threshold=14):\n",
        "    y_pred = []\n",
        "\n",
        "    for posts in X_test:\n",
        "        scores = generate_ratings(posts, assessment_items, stop_words)\n",
        "        total_score = sum(scores)\n",
        "        predicted_label = 1 if total_score >= threshold else 0\n",
        "        y_pred.append(predicted_label)\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "X_test=test_data['selected_posts']\n",
        "X_test = X_test.apply(lambda x: [preprocess_text(post, stop_words) for post in x])\n",
        "y_test=y_true_test\n",
        "y_test= pd.factorize(y_test)[0]\n",
        "\n",
        "# Apply the rule-based method to the test set\n",
        "y_pred = evaluate_rule_based_method(X_test, y_test, eating_disorder_items, stop_words)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 100\n",
        "\n",
        "# Bootstrap sampling and evaluation\n",
        "f1_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "\n",
        "for _ in range(num_bootstraps):\n",
        "    bootstrap_indices = np.random.choice(len(y_test), size=len(y_test), replace=True)\n",
        "    y_test_bootstrap = y_test[bootstrap_indices]\n",
        "    y_pred_bootstrap = [y_pred[i] for i in bootstrap_indices]\n",
        "\n",
        "    f1 = f1_score(y_test_bootstrap, y_pred_bootstrap)\n",
        "    precision = precision_score(y_test_bootstrap, y_pred_bootstrap)\n",
        "    recall = recall_score(y_test_bootstrap, y_pred_bootstrap)\n",
        "\n",
        "    f1_scores.append(f1)\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "\n",
        "# Calculate mean and standard deviation of scores\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Mean F1 Score: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
        "print(f\"Mean Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
        "print(f\"Mean Recall: {mean_recall:.4f} ± {std_recall:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQiafIvDxNIo",
        "outputId": "e8458af5-258f-4480-e6d5-170c99afe5b7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean F1 Score: 0.0000 ± 0.0000\n",
            "Mean Precision: 0.0000 ± 0.0000\n",
            "Mean Recall: 0.0000 ± 0.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# assessment-all\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "def calculate_eating_disorder_score(user_posts, assessment_items, stop_words):\n",
        "    scores = []\n",
        "    for item_list in assessment_items:\n",
        "        count = sum(any(keyword.lower() in post.lower() for keyword in item_list) for post in user_posts)\n",
        "        score = min(count, 3)  # Limit the score to a maximum of 3 based on the checklist scale\n",
        "        scores.append(score)\n",
        "    return scores\n",
        "\n",
        "def evaluate_rule_based_method(X, y, assessment_items, stop_words, threshold=14):\n",
        "    y_pred = []\n",
        "\n",
        "    for posts in X:\n",
        "        scores = calculate_eating_disorder_score(posts, assessment_items, stop_words)\n",
        "        total_score = sum(scores)\n",
        "        predicted_label = 1 if total_score >= threshold else 0\n",
        "        y_pred.append(predicted_label)\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: [preprocess_text(post, stop_words) for post in x])\n",
        "\n",
        "# Eating disorder assessment items\n",
        "eating_disorder_items = [\n",
        "    ['limit food', 'restrict eating', 'influence weight', 'influence shape'],\n",
        "    ['long periods without eating', 'fasting', 'skipping meals'],\n",
        "    ['thinking about food', 'preoccupied with food', 'thinking about calories'],\n",
        "    ['thinking about weight', 'thinking about shape', 'preoccupied with weight', 'preoccupied with shape'],\n",
        "    ['fear of gaining weight', 'afraid of becoming fat'],\n",
        "    ['desire to lose weight', 'want to be thinner'],\n",
        "    ['making yourself sick', 'vomiting', 'taking laxatives'],\n",
        "    ['excessive exercise', 'driven exercise', 'compulsive exercise'],\n",
        "    ['loss of control over eating', 'binge eating'],\n",
        "    ['eating large amounts of food', 'overeating'],\n",
        "    ['weight influences self-evaluation', 'shape influences self-evaluation']\n",
        "]\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = all_data['selected_posts']\n",
        "y = y_true_train # Assuming 'eating_disorder' is the column containing the eating disorder labels\n",
        "\n",
        "# Convert the target variable to numerical labels\n",
        "y = pd.factorize(y)[0]\n",
        "\n",
        "# Number of folds for cross-validation\n",
        "num_folds = 5\n",
        "\n",
        "# Initialize KFold cross-validator\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Lists to store evaluation scores for each fold\n",
        "f1_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Apply the rule-based method to the test fold\n",
        "    y_pred = evaluate_rule_based_method(X_test, y_test, eating_disorder_items, stop_words)\n",
        "\n",
        "    # Calculate evaluation scores for the current fold\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "\n",
        "    f1_scores.append(f1)\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "\n",
        "# Calculate mean and standard deviation of scores across all folds\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Mean F1 Score: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
        "print(f\"Mean Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
        "print(f\"Mean Recall: {mean_recall:.4f} ± {std_recall:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVtc_UTtzWT0"
      },
      "source": [
        "### **schizophrenia**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNPKoBcucjv8",
        "outputId": "64f9a80b-8457-4f52-e09d-4821da77f777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-138-8ff7b7adb78b>:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_data['selected_posts'] = test_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard Deviation of F1 Scores (Bootstrap): 0.07430064502958214\n",
            "Standard Deviation of Recall Scores (Bootstrap): 0.043969943719048575\n",
            "Standard Deviation of Precision Scores (Bootstrap): 0.0006764067236959868\n",
            "f1_score 0.13126933859239062\n",
            "recall 0.0719904587361002\n",
            "precision 0.9989400921658987\n",
            "std_f1_score 0.07430064502958214\n",
            "std_recall_score 0.043969943719048575\n",
            "std_precision_score 0.0006764067236959868\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#baseline+test\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "\n",
        "!python -m nltk.downloader stopwords\n",
        "# Load the trained model and vectorizer\n",
        "model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "vectorizer = TfidfVectorizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Load and preprocess the training data\n",
        "train_data['selected_posts'] = train_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "test_data['selected_posts'] = test_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Preprocess the text data\n",
        "X_train = vectorizer.fit_transform(train_data['selected_posts'])\n",
        "X_test = vectorizer.transform(test_data['selected_posts'])\n",
        "y_train = y_true_train  # Assuming 'anxiety' is the column containing the anxiety labels in the training data\n",
        "y_test = y_true_test  # Assuming 'anxiety' is the column containing the anxiety labels in the test data\n",
        "# Perform cross-validation\n",
        "model.fit(X_train, y_train)\n",
        "predictions=model.predict(X_test)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 100\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    sensitivity = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    specificity = recall_score(np.logical_not(true_labels) , np.logical_not(bootstrap_preds))\n",
        "    return f1, sensitivity, specificity\n",
        "\n",
        "# Generate bootstrap samples and calculate scores\n",
        "bootstrap_scores_list = [bootstrap_scores(y_test, predictions) for _ in range(num_bootstraps)]\n",
        "\n",
        "# Calculate standard deviation of scores\n",
        "f1_scores, recall_scores, precision_scores = zip(*bootstrap_scores_list)\n",
        "std_f1_score = np.std(f1_scores)\n",
        "std_recall_score = np.std(recall_scores)\n",
        "std_precision_score = np.std(precision_scores)\n",
        "\n",
        "# Print results\n",
        "print(\"Standard Deviation of F1 Scores (Bootstrap):\", std_f1_score)\n",
        "print(\"Standard Deviation of Recall Scores (Bootstrap):\", std_recall_score)\n",
        "print(\"Standard Deviation of Precision Scores (Bootstrap):\", std_precision_score)\n",
        "\n",
        "# Print results\n",
        "print(\"f1_score\", np.mean(f1_scores))\n",
        "print(\"recall\", np.mean(recall_scores))\n",
        "print(\"precision\", np.mean(precision_scores))\n",
        "print(\"std_f1_score\", std_f1_score)\n",
        "print(\"std_recall_score\", std_recall_score)\n",
        "print(\"std_precision_score\", std_precision_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRoN5z9ydSsv",
        "outputId": "c70d76ad-3259-4fdd-a7e7-484a28e2eb17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Cross-validation scores:\n",
            "F1 Score: 0.1202 ± 0.0527\n",
            "Sensitivity: 0.0754 ± 0.0360\n",
            "Specificity: 0.9979 ± 0.0042\n"
          ]
        }
      ],
      "source": [
        "#simple+all\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "# Load the trained model and vectorizer\n",
        "model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "vectorizer = TfidfVectorizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Function to calculate specificity\n",
        "def specificity_score(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    sensitivity = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    specificity = recall_score(np.logical_not(true_labels) , np.logical_not(bootstrap_preds))\n",
        "    return f1, sensitivity, specificity\n",
        "\n",
        "\n",
        "# Load and preprocess the training data\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Preprocess the text data\n",
        "X = vectorizer.fit_transform(all_data['selected_posts'])\n",
        "y = y_all\n",
        "\n",
        "\n",
        "# Define the scoring metrics\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(specificity_score)\n",
        "}\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(model, X, y, cv=5, scoring=scoring, return_estimator=True, return_indices=True)\n",
        "\n",
        "# Calculate the mean and standard deviation of the scores\n",
        "f1_mean = np.mean(cv_scores['test_f1'])\n",
        "f1_std = np.std(cv_scores['test_f1'])\n",
        "sensitivity_mean = np.mean(cv_scores['test_sensitivity'])\n",
        "sensitivity_std = np.std(cv_scores['test_sensitivity'])\n",
        "specificity_mean = np.mean(cv_scores['test_specificity'])\n",
        "specificity_std = np.std(cv_scores['test_specificity'])\n",
        "'''\n",
        "# Get the predictions for each fold\n",
        "fold_predictions_cross = []\n",
        "for estimator, test_index in zip(cv_scores['estimator'], cv_scores['indices']['test']):\n",
        "    print(test_index)\n",
        "    X_test_fold = X_combined.tocsr()[test_index]\n",
        "    y_test_fold = y[test_index]\n",
        "    y_pred_fold = estimator.predict(X_test_fold)\n",
        "    fold_predictions_cross.append((y_test_fold, y_pred_fold))\n",
        "'''\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} ± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} ± {specificity_std:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBWmyywZ4kQN"
      },
      "outputs": [],
      "source": [
        "schizophrenia_items = [\n",
        "    \"strange surroundings\",\n",
        "    \"unusual sounds\",\n",
        "    \"visual disturbances\",\n",
        "    \"telepathy\",\n",
        "    \"thought control\",\n",
        "    \"difficulty communicating\",\n",
        "    \"unusually gifted\",\n",
        "    \"feeling watched\",\n",
        "    \"strange skin sensations\",\n",
        "    \"distracted by distant sounds\",\n",
        "    \"unseen presence\",\n",
        "    \"worry about mental health\",\n",
        "    \"feeling non-existent\",\n",
        "    \"confusion between real and imaginary\",\n",
        "    \"unusual beliefs\",\n",
        "    \"changed body parts\",\n",
        "    \"loud thoughts\",\n",
        "    \"mistrust\",\n",
        "    \"unusual visual phenomena\",\n",
        "    \"seeing things others can't\",\n",
        "    \"difficulty being understood\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI2G0EdK1jfh",
        "outputId": "41544bcc-ab78-4356-c454-ca267c619935"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation scores:\n",
            "F1 Score: 0.0000 ± 0.0000\n",
            "Sensitivity: 0.0000 ± 0.0000\n",
            "Specificity: 0.0000 ± 0.0000\n"
          ]
        }
      ],
      "source": [
        "# assessment-test\n",
        "!pip install -U scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "def generate_ratings(user_posts, assessment_items, vectorizer, stop_words):\n",
        "    user_ratings = []\n",
        "    for item in assessment_items:\n",
        "        count = sum(item.lower() in post.lower() for post in user_posts)\n",
        "        rating = min(count, 1)  # Limit the rating to a maximum of 1 based on the checklist scale\n",
        "        user_ratings.append(rating)\n",
        "    return user_ratings\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: [preprocess_text(post, stop_words) for post in x])\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X_text = all_data['selected_posts']\n",
        "y = y_true_train  # Assuming 'schizophrenia' is the column containing the schizophrenia disorder labels\n",
        "\n",
        "# Convert the target variable to numerical labels\n",
        "y = pd.factorize(y)[0]\n",
        "\n",
        "# Convert text to Bag-of-Words representation\n",
        "vectorizer = CountVectorizer()\n",
        "X_text_vec = vectorizer.fit_transform([' '.join(posts) for posts in X_text])\n",
        "\n",
        "X_ratings = []\n",
        "for _, row in all_data.iterrows():\n",
        "    user_posts = row['selected_posts']\n",
        "    user_ratings = generate_ratings(user_posts, schizophrenia_items, vectorizer, stop_words)\n",
        "    X_ratings.append(user_ratings)\n",
        "\n",
        "# Convert ratings to a numpy array\n",
        "X_ratings = np.array(X_ratings)\n",
        "\n",
        "# Combine text features and rating features\n",
        "X_combined = hstack([X_text_vec, X_ratings])\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Define the scoring metrics\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(lambda y_true, y_pred: precision_score(y_true, y_pred))\n",
        "}\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(rf_classifier, X_text_vec, y, cv=5, scoring=scoring, return_estimator=True, return_train_score=True)\n",
        "\n",
        "# Calculate the mean and standard deviation of the scores\n",
        "f1_mean = np.mean(cv_scores['test_f1'])\n",
        "f1_std = np.std(cv_scores['test_f1'])\n",
        "sensitivity_mean = np.mean(cv_scores['test_sensitivity'])\n",
        "sensitivity_std = np.std(cv_scores['test_sensitivity'])\n",
        "specificity_mean = np.mean(cv_scores['test_specificity'])\n",
        "specificity_std = np.std(cv_scores['test_specificity'])\n",
        "\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} ± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} ± {specificity_std:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbrRzga-4OJs",
        "outputId": "72b26285-6bf3-4fd9-b63a-3a56c784ab4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard Deviation of F1 Scores (Bootstrap): 0.0\n",
            "Standard Deviation of Recall Scores (Bootstrap): 0.0\n",
            "Standard Deviation of Precision Scores (Bootstrap): 0.0\n",
            "f1_score 0.0\n",
            "recall 0.0\n",
            "precision 0.0\n",
            "std_f1_score 0.0\n",
            "std_recall_score 0.0\n",
            "std_precision_score 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# assessment-all\n",
        "#!pip install -U scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "def generate_ratings(user_posts, assessment_items, vectorizer, stop_words):\n",
        "    user_ratings = []\n",
        "    for item in assessment_items:\n",
        "        count = sum(item.lower() in post.lower() for post in user_posts)\n",
        "        rating = min(count, 1)  # Limit the rating to a maximum of 1 based on the schizophrenia checklist scale\n",
        "        user_ratings.append(rating)\n",
        "    return user_ratings\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: [preprocess_text(post, stop_words) for post in x])\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X_text = all_data['selected_posts']\n",
        "y = y_true_train\n",
        "\n",
        "# Convert the target variable to numerical labels\n",
        "y = pd.factorize(y)[0]\n",
        "\n",
        "# Convert text to Bag-of-Words representation\n",
        "vectorizer = CountVectorizer()\n",
        "X_text_vec = vectorizer.fit_transform([' '.join(posts) for posts in X_text])\n",
        "\n",
        "# Generate ratings for each data point\n",
        "X_ratings = []\n",
        "for _, row in all_data.iterrows():\n",
        "    user_posts = row['selected_posts']\n",
        "    user_ratings = generate_ratings(user_posts, schizophrenia_items, vectorizer, stop_words)\n",
        "    X_ratings.append(user_ratings)\n",
        "\n",
        "# Convert ratings to a numpy array\n",
        "X_ratings = np.array(X_ratings)\n",
        "\n",
        "# Determine the presence of schizophrenia based on a threshold of 6\n",
        "schizophrenia_threshold = 6\n",
        "X_schizophrenia = np.where(np.sum(X_ratings, axis=1) >= schizophrenia_threshold, 1, 0)\n",
        "\n",
        "# Combine text features and schizophrenia presence\n",
        "X_combined = hstack([X_text_vec, X_schizophrenia.reshape(-1, 1)])\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "X_combined = X_combined.tocsr()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "predictions = rf_classifier.predict(X_test)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 100\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    recall = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    precision = precision_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    return f1, recall, precision\n",
        "\n",
        "# Generate bootstrap samples and calculate scores\n",
        "bootstrap_scores_list = [bootstrap_scores(y_test, predictions) for _ in range(num_bootstraps)]\n",
        "\n",
        "# Calculate standard deviation of scores\n",
        "f1_scores, recall_scores, precision_scores = zip(*bootstrap_scores_list)\n",
        "std_f1_score = np.std(f1_scores)\n",
        "std_recall_score = np.std(recall_scores)\n",
        "std_precision_score = np.std(precision_scores)\n",
        "\n",
        "# Print results\n",
        "print(\"Standard Deviation of F1 Scores (Bootstrap):\", std_f1_score)\n",
        "print(\"Standard Deviation of Recall Scores (Bootstrap):\", std_recall_score)\n",
        "print(\"Standard Deviation of Precision Scores (Bootstrap):\", std_precision_score)\n",
        "\n",
        "# Print results\n",
        "print(\"f1_score\", np.mean(f1_scores))\n",
        "print(\"recall\", np.mean(recall_scores))\n",
        "print(\"precision\", np.mean(precision_scores))\n",
        "print(\"std_f1_score\", std_f1_score)\n",
        "print(\"std_recall_score\", std_recall_score)\n",
        "print(\"std_precision_score\", std_precision_score)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
