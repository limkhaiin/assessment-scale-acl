{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90fHqUAKpAhR"
      },
      "outputs": [],
      "source": [
        "clauimport os\n",
        "\n",
        "project_folder = \"/content/drive/MyDrive/Colab_Notebooks/MDDdataset/symptom_sum_top16/claude_results\"\n",
        "\n",
        "def create_and_set_working_directory(project_folder):\n",
        "  # check if your project folder exists. if not, it will be created.\n",
        "  if os.path.isdir(project_folder) == False:\n",
        "    os.mkdir(project_folder)\n",
        "    print(project_folder + ' did not exist but was created.')\n",
        "\n",
        "  # change the OS to use your project folder as the working directory\n",
        "  os.chdir(project_folder)\n",
        "create_and_set_working_directory(project_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jldo2m77pSaR"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/Colab_Notebooks/MDDdataset/symptom_sum_top16/test.pkl', 'rb') as f:\n",
        "      raw_test_data = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/Colab_Notebooks/MDDdataset/symptom_sum_top16/val.pkl', 'rb') as f:\n",
        "      raw_val_data = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/Colab_Notebooks/MDDdataset/symptom_sum_top16/train.pkl', 'rb') as f:\n",
        "      raw_train_data = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLRSWR9iqXke"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train_data=pd.DataFrame(raw_train_data)\n",
        "test_data_diseases=pd.DataFrame(raw_test_data)\n",
        "val_data=pd.DataFrame(raw_val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2h1VjkMwOT2"
      },
      "outputs": [],
      "source": [
        "test_data=test_data_diseases[['id', 'selected_posts']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuKO3Skhpcwz"
      },
      "outputs": [],
      "source": [
        "all_data = pd.concat([train_data, val_data], axis=0, ignore_index=True)\n",
        "all_data = pd.concat([all_data, test_data_diseases], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RmXS1vo1yiN"
      },
      "outputs": [],
      "source": [
        "y_true_train=[]\n",
        "for row in all_data['diseases']:\n",
        "  if 'adhd' in row:\n",
        "    y_true_train.append(1)\n",
        "  else:\n",
        "    y_true_train.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0zPczu518Fv"
      },
      "outputs": [],
      "source": [
        "y_true_test=[]\n",
        "for row in test_data_diseases['diseases']:\n",
        "  if 'adhd' in row:\n",
        "    y_true_test.append(1)\n",
        "  else:\n",
        "    y_true_test.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TayoyceNROWv"
      },
      "outputs": [],
      "source": [
        "y_train_best=np.load('y_train_best.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoGw7FiGauVU"
      },
      "source": [
        "### **Claude 3, all_data, test_data (non-assessment scale)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzNRc_X0d8Cy"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jaWXi-4YZ-G",
        "outputId": "93c51774-f1c8-45a8-b5c0-fc7689e33b05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Standard Deviation of F1 Scores (Bootstrap): 0.035015867824789694\n",
            "Standard Deviation of Recall Scores (Bootstrap): 0.028756520982582138\n",
            "Standard Deviation of Precision Scores (Bootstrap): 0.045588253142936214\n",
            "f1_score 0.3902573661161953\n",
            "recall 0.26028061006528447\n",
            "precision 0.785713762226094\n",
            "std_f1_score 0.035015867824789694\n",
            "std_recall_score 0.028756520982582138\n",
            "std_precision_score 0.045588253142936214\n"
          ]
        }
      ],
      "source": [
        "#baseline+test\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "\n",
        "!python -m nltk.downloader stopwords\n",
        "# Load the trained model and vectorizer\n",
        "model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "vectorizer = TfidfVectorizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Load and preprocess the training data\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Train the model\n",
        "X = vectorizer.fit_transform(all_data['selected_posts'])\n",
        "y = y_true_train\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "# Perform cross-validation\n",
        "model.fit(X_train, y_train)\n",
        "predictions=model.predict(X_test)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 1000\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    recall = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    precision = precision_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    return f1, recall, precision\n",
        "\n",
        "# Generate bootstrap samples and calculate scores\n",
        "bootstrap_scores_list = [bootstrap_scores(y_true_test, predictions) for _ in range(num_bootstraps)]\n",
        "\n",
        "# Calculate standard deviation of scores\n",
        "f1_scores, recall_scores, precision_scores = zip(*bootstrap_scores_list)\n",
        "std_f1_score = np.std(f1_scores)\n",
        "std_recall_score = np.std(recall_scores)\n",
        "std_precision_score = np.std(precision_scores)\n",
        "\n",
        "# Print results\n",
        "print(\"Standard Deviation of F1 Scores (Bootstrap):\", std_f1_score)\n",
        "print(\"Standard Deviation of Recall Scores (Bootstrap):\", std_recall_score)\n",
        "print(\"Standard Deviation of Precision Scores (Bootstrap):\", std_precision_score)\n",
        "\n",
        "# Print results\n",
        "print(\"f1_score\", np.mean(f1_scores))\n",
        "print(\"recall\", np.mean(recall_scores))\n",
        "print(\"precision\", np.mean(precision_scores))\n",
        "print(\"std_f1_score\", std_f1_score)\n",
        "print(\"std_recall_score\", std_recall_score)\n",
        "print(\"std_precision_score\", std_precision_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpgPooS79Kdg"
      },
      "outputs": [],
      "source": [
        "with open('adhd-test-simple.npy', 'wb') as f:\n",
        "    np.save(f, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFY70SGdFwTV",
        "outputId": "9f4ad313-1b29-4a42-8b20-018b1abb3052"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Cross-validation scores:\n",
            "F1 Score: 0.3921 Â± 0.1020\n",
            "Sensitivity: 0.2881 Â± 0.0473\n",
            "Specificity: 0.7786 Â± 0.3102\n"
          ]
        }
      ],
      "source": [
        "#baseline+all\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "\n",
        "# Load the trained model and vectorizer\n",
        "model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "vectorizer = TfidfVectorizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    recall = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    precision = precision_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    return f1, recall, precision\n",
        "\n",
        "\n",
        "# Load and preprocess the training data\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Preprocess the text data\n",
        "X = vectorizer.fit_transform(all_data['selected_posts'])\n",
        "y = y_true_train\n",
        "\n",
        "\n",
        "# Define the scoring metrics\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(lambda y_true, y_pred: precision_score(y_true, y_pred))\n",
        "}\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(model, X, y, cv=5, scoring=scoring, return_estimator=True, return_indices=True)\n",
        "\n",
        "# Calculate the mean and standard deviation of the scores\n",
        "f1_mean = np.mean(cv_scores['test_f1'])\n",
        "f1_std = np.std(cv_scores['test_f1'])\n",
        "sensitivity_mean = np.mean(cv_scores['test_sensitivity'])\n",
        "sensitivity_std = np.std(cv_scores['test_sensitivity'])\n",
        "specificity_mean = np.mean(cv_scores['test_specificity'])\n",
        "specificity_std = np.std(cv_scores['test_specificity'])\n",
        "'''\n",
        "# Get the predictions for each fold\n",
        "fold_predictions_cross = []\n",
        "for estimator, test_index in zip(cv_scores['estimator'], cv_scores['indices']['test']):\n",
        "    print(test_index)\n",
        "    X_test_fold = X_combined.tocsr()[test_index]\n",
        "    y_test_fold = y[test_index]\n",
        "    y_pred_fold = estimator.predict(X_test_fold)\n",
        "    fold_predictions_cross.append((y_test_fold, y_pred_fold))\n",
        "'''\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} Â± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} Â± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} Â± {specificity_std:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgpYuHdlGeRP"
      },
      "outputs": [],
      "source": [
        "with open('adhd-all-simple.npy', 'wb') as f:\n",
        "    np.save(f, cv_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9WMVTSma3qv"
      },
      "source": [
        "### **ADHD**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jMo32xmHisD"
      },
      "outputs": [],
      "source": [
        "checklist_items = [\n",
        "    # ATTENTION 314.00 (â¥6/9)\n",
        "    'Fails to give close attention to details, careless mistakes',\n",
        "    'Difficulty sustaining attention in tasks or fun activities',\n",
        "    'Does not seem to listen when spoken to directly',\n",
        "    'Does not follow through on instructions and fails to finish work',\n",
        "    'Difficulty organizing tasks and activities',\n",
        "    'Avoids tasks that require sustained mental effort (boring)',\n",
        "    'Losing things',\n",
        "    'Easily distracted',\n",
        "    'Forgetful in daily activities',\n",
        "\n",
        "    # HYPERACTIVE/IMPULSIVE 314.01 (â¥6/9)\n",
        "    'Fidgety or squirms in seat',\n",
        "    'Leaves seat when sitting is expected',\n",
        "    'Feels restless',\n",
        "    'Difficulty in doing fun things quietly',\n",
        "    'Always on the go or acts as if \"driven by a motor\"',\n",
        "    'Talks excessively',\n",
        "    'Blurts answers before questions have been completed',\n",
        "    'Difficulty awaiting turn',\n",
        "    'Interrupting or intruding on others',\n",
        "\n",
        "    # OPPOSITIONAL DEFIANT DISORDER 313.81 (>4/8)\n",
        "    'Loses temper',\n",
        "    'Argues with adults',\n",
        "    'Actively defies or refuses to comply with requests or rules',\n",
        "    'Deliberately annoys people',\n",
        "    'Blames others for his or her mistakes or misbehavior',\n",
        "    'Touchy or easily annoyed by others',\n",
        "    'Angry or resentful',\n",
        "    'Spiteful or vindictive'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip-JQzn_bHSn",
        "outputId": "c60f7353-9256-4154-fcaf-89ab3cb349b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#baseline+test\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the trained model and vectorizer\n",
        "model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "vectorizer = TfidfVectorizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds, average='weighted')\n",
        "    recall = recall_score(bootstrap_true_labels, bootstrap_preds, average='weighted')\n",
        "    precision = precision_score(bootstrap_true_labels, bootstrap_preds, average='weighted')\n",
        "    return f1, recall, precision\n",
        "\n",
        "# Load and preprocess the training data\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Preprocess the text data\n",
        "X_text = vectorizer.fit_transform(all_data['selected_posts'])\n",
        "\n",
        "\n",
        "X_ratings = []\n",
        "for _, row in all_data.iterrows():\n",
        "    user_posts = row['selected_posts']\n",
        "    user_ratings = [int(item.lower() in user_posts.lower()) for item in checklist_items]\n",
        "    X_ratings.append(user_ratings)\n",
        "\n",
        "X_ratings = np.array(X_ratings)\n",
        "\n",
        "# Combine text features and rating features\n",
        "X_combined = np.hstack((X_text.toarray(), X_ratings))\n",
        "\n",
        "y = y_true_train\n",
        "\n",
        "# Define the scoring metrics\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score, average='weighted'),\n",
        "    'sensitivity': make_scorer(recall_score, average='weighted'),\n",
        "    'specificity': make_scorer(lambda y_true, y_pred: precision_score(y_true, y_pred, average='weighted'))\n",
        "}\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(model, X_combined, y, cv=5, scoring=scoring, return_estimator=True)\n",
        "\n",
        "# Calculate the mean and standard deviation of the scores\n",
        "f1_mean = np.mean(cv_scores['test_f1'])\n",
        "f1_std = np.std(cv_scores['test_f1'])\n",
        "sensitivity_mean = np.mean(cv_scores['test_sensitivity'])\n",
        "sensitivity_std = np.std(cv_scores['test_sensitivity'])\n",
        "specificity_mean = np.mean(cv_scores['test_specificity'])\n",
        "specificity_std = np.std(cv_scores['test_specificity'])\n",
        "\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} Â± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} Â± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} Â± {specificity_std:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "fgwvh6f-5BxJ",
        "outputId": "77b03945-0290-4582-a334-21a589fc809c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 187, in _run_module_as_main\n",
            "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 110, in _get_module_details\n",
            "    __import__(pkg_name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nltk/__init__.py\", line 133, in <module>\n",
            "    from nltk.collocations import *\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nltk/collocations.py\", line 36, in <module>\n",
            "    from nltk.metrics import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nltk/metrics/__init__.py\", line 17, in <module>\n",
            "    from nltk.metrics.aline import align\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nltk/metrics/aline.py\", line 41, in <module>\n",
            "    import numpy as np\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/__init__.py\", line 139, in <module>\n",
            "    from . import core\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/core/__init__.py\", line 71, in <module>\n",
            "    from . import numerictypes as nt\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/core/numerictypes.py\", line 105, in <module>\n",
            "    from ._type_aliases import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/core/_type_aliases.py\", line 23, in <module>\n",
            "    from numpy.core._dtype import _kind_name\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1012, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 672, in _compile_bytecode\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'y_true_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1863beb9fff6>\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_true_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m# Convert the target variable to numerical labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_true_train' is not defined"
          ]
        }
      ],
      "source": [
        "#baseline+all\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "def predict_ratings(checklist_items, model, vectorizer, stop_words):\n",
        "    # Preprocess the checklist items\n",
        "    preprocessed_items = [preprocess_text(item, stop_words) for item in checklist_items]\n",
        "\n",
        "    # Convert checklist items to TF-IDF vectors\n",
        "    item_vectors = vectorizer.transform(preprocessed_items)\n",
        "\n",
        "    # Predict ratings using the trained model\n",
        "    predicted_ratings = model.predict(item_vectors)\n",
        "\n",
        "    return predicted_ratings\n",
        "\n",
        "def is_adhd_patient(checklist_items, model, vectorizer, stop_words):\n",
        "    # Define the thresholds for each section\n",
        "    section_thresholds = {\n",
        "        'attention': 6,\n",
        "        'hyperactive_impulsive': 6,\n",
        "        'oppositional_defiant': 4\n",
        "    }\n",
        "\n",
        "    # Initialize variables to store the count of items with ratings 2 and 3\n",
        "    section_counts = {\n",
        "        'attention': 0,\n",
        "        'hyperactive_impulsive': 0,\n",
        "        'oppositional_defiant': 0\n",
        "    }\n",
        "\n",
        "    # Predict ratings for the checklist items\n",
        "    predicted_ratings = predict_ratings(checklist_items, model, vectorizer, stop_words)\n",
        "\n",
        "    # Iterate over each item and its predicted rating\n",
        "    for item, rating in zip(checklist_items, predicted_ratings):\n",
        "        # Determine the section of the item based on its name\n",
        "        if 'ATTENTION' in item:\n",
        "            section = 'attention'\n",
        "        elif 'HYPERACTIVE/IMPULSIVE' in item:\n",
        "            section = 'hyperactive_impulsive'\n",
        "        else:\n",
        "            section = 'oppositional_defiant'\n",
        "\n",
        "        # Increment the count if the rating is 2 or 3\n",
        "        if rating >= 2:\n",
        "            section_counts[section] += 1\n",
        "\n",
        "    # Check if any section exceeds its threshold\n",
        "    for section, count in section_counts.items():\n",
        "        if count >= section_thresholds[section]:\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "'''\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "'''\n",
        "# Split the data into features (X) and target (y)\n",
        "\n",
        "X = all_data['selected_posts']\n",
        "y = y_true_train\n",
        "\n",
        "# Convert the target variable to numerical labels\n",
        "y = pd.factorize(y)[0]\n",
        "\n",
        "# Convert text to Bag-of-Words representation\n",
        "vectorizer = CountVectorizer()\n",
        "X_vec = vectorizer.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.1)\n",
        "\n",
        "# Convert text to Bag-of-Words representation\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Define the scoring metrics\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score, average='weighted'),\n",
        "    'sensitivity': make_scorer(recall_score, average='weighted'),\n",
        "    'specificity': make_scorer(lambda y_true, y_pred: precision_score(y_true, y_pred, average='weighted'))\n",
        "}\n",
        "\n",
        "# Calculate the mean and standard deviation of the scores\n",
        "f1_mean = np.mean(cv_scores['test_f1'])\n",
        "f1_std = np.std(cv_scores['test_f1'])\n",
        "sensitivity_mean = np.mean(cv_scores['test_sensitivity'])\n",
        "sensitivity_std = np.std(cv_scores['test_sensitivity'])\n",
        "specificity_mean = np.mean(cv_scores['test_specificity'])\n",
        "specificity_std = np.std(cv_scores['test_specificity'])\n",
        "predictions_list = cv_scores['test_predictions']\n",
        "\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} Â± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} Â± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} Â± {specificity_std:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90nlDi5BUUXr",
        "outputId": "5ac06cbb-1936-4af7-f197-445e9ececa49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Standard Deviation of F1 Scores (Bootstrap): 0.008695428863183368\n",
            "Standard Deviation of Recall Scores (Bootstrap): 0.004453362373831768\n",
            "Standard Deviation of Precision Scores (Bootstrap): 0.17063807140520212\n",
            "f1_score 0.020997814812753948\n",
            "recall 0.010649207581614917\n",
            "precision 0.8532427849927849\n",
            "std_f1_score 0.008695428863183368\n",
            "std_recall_score 0.004453362373831768\n",
            "std_precision_score 0.17063807140520212\n"
          ]
        }
      ],
      "source": [
        "#assessment+ test\n",
        "#!pip install -U scikit-learn\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.sparse import hstack\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "def generate_ratings(user_posts, assessment_items, vectorizer, stop_words):\n",
        "    user_ratings = []\n",
        "    for item in assessment_items:\n",
        "        if any(item.lower() in post.lower() for post in user_posts):\n",
        "            user_ratings.append(1)  # Item is present in user's posts\n",
        "        else:\n",
        "            user_ratings.append(0)  # Item is not present in user's posts\n",
        "    return user_ratings\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: [preprocess_text(post, stop_words) for post in x])\n",
        "\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X_text = all_data['selected_posts']\n",
        "y = y_true_train\n",
        "\n",
        "# Convert the target variable to numerical labels\n",
        "y = pd.factorize(y)[0]\n",
        "\n",
        "np.random.seed(42)  # Set a fixed random seed\n",
        "# Convert text to Bag-of-Words representation\n",
        "vectorizer = CountVectorizer()\n",
        "X_text_vec = vectorizer.fit_transform([' '.join(posts) for posts in X_text])\n",
        "\n",
        "# Generate ratings for each data point\n",
        "X_ratings = []\n",
        "for _, row in all_data.iterrows():\n",
        "    user_posts = row['selected_posts']\n",
        "    user_ratings = generate_ratings(user_posts, checklist_items, vectorizer, stop_words)\n",
        "    X_ratings.append(user_ratings)\n",
        "\n",
        "# Convert ratings to a numpy array\n",
        "X_ratings = np.array(X_ratings)\n",
        "\n",
        "# Combine text features and rating features\n",
        "X_combined = hstack([X_text_vec, X_ratings])\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "#train a model\n",
        "X_combined=X_combined.tocsr()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "predictions=rf_classifier.predict(X_test)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 100\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    recall = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    precision = precision_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    return f1, recall, precision\n",
        "\n",
        "# Generate bootstrap samples and calculate scores\n",
        "bootstrap_scores_list = [bootstrap_scores(y_test, predictions) for _ in range(num_bootstraps)]\n",
        "\n",
        "# Calculate standard deviation of scores\n",
        "f1_scores, recall_scores, precision_scores = zip(*bootstrap_scores_list)\n",
        "std_f1_score = np.std(f1_scores)\n",
        "std_recall_score = np.std(recall_scores)\n",
        "std_precision_score = np.std(precision_scores)\n",
        "\n",
        "# Print results\n",
        "print(\"Standard Deviation of F1 Scores (Bootstrap):\", std_f1_score)\n",
        "print(\"Standard Deviation of Recall Scores (Bootstrap):\", std_recall_score)\n",
        "print(\"Standard Deviation of Precision Scores (Bootstrap):\", std_precision_score)\n",
        "\n",
        "# Print results\n",
        "print(\"f1_score\", np.mean(f1_scores))\n",
        "print(\"recall\", np.mean(recall_scores))\n",
        "print(\"precision\", np.mean(precision_scores))\n",
        "print(\"std_f1_score\", std_f1_score)\n",
        "print(\"std_recall_score\", std_recall_score)\n",
        "print(\"std_precision_score\", std_precision_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SVbYG2r91wS"
      },
      "outputs": [],
      "source": [
        "with open('adhd-test-assessment.npy', 'wb') as f:\n",
        "    np.save(f, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQx2S6ghB5JO"
      },
      "outputs": [],
      "source": [
        "with open('adhd-test-assessment-Xtest.npy', 'wb') as f:\n",
        "    np.save(f, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daL_BJuz_KI3",
        "outputId": "9778a36b-4f96-4188-e21b-27d005fbb6dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation scores:\n",
            "F1 Score: 0.0259 Â± 0.0355\n",
            "Sensitivity: 0.0156 Â± 0.0230\n",
            "Specificity: 0.5043 Â± 0.3654\n"
          ]
        }
      ],
      "source": [
        "#assessment+ all\n",
        "!pip install -U scikit-learn\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.sparse import hstack\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "def generate_ratings(user_posts, assessment_items, vectorizer, stop_words):\n",
        "    user_ratings = []\n",
        "    for item in assessment_items:\n",
        "        if any(item.lower() in post.lower() for post in user_posts):\n",
        "            user_ratings.append(1)  # Item is present in user's posts\n",
        "        else:\n",
        "            user_ratings.append(0)  # Item is not present in user's posts\n",
        "    return user_ratings\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: [preprocess_text(post, stop_words) for post in x])\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X_text = all_data['selected_posts']\n",
        "y = y_true_train\n",
        "\n",
        "# Convert the target variable to numerical labels\n",
        "y = pd.factorize(y)[0]\n",
        "\n",
        "# Convert text to Bag-of-Words representation\n",
        "vectorizer = CountVectorizer()\n",
        "X_text_vec = vectorizer.fit_transform([' '.join(posts) for posts in X_text])\n",
        "\n",
        "# Generate ratings for each data point\n",
        "X_ratings = []\n",
        "for _, row in all_data.iterrows():\n",
        "    user_posts = row['selected_posts']\n",
        "    user_ratings = generate_ratings(user_posts, checklist_items, vectorizer, stop_words)\n",
        "    X_ratings.append(user_ratings)\n",
        "\n",
        "# Convert ratings to a numpy array\n",
        "X_ratings = np.array(X_ratings)\n",
        "\n",
        "# Combine text features and rating features\n",
        "X_combined = hstack([X_text_vec, X_ratings])\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Define the scoring metrics\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(lambda y_true, y_pred: precision_score(y_true, y_pred))\n",
        "}\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(rf_classifier, X_combined, y, cv=5, scoring=scoring, return_estimator=True, return_indices=True)\n",
        "\n",
        "# Calculate the mean and standard deviation of the scores\n",
        "f1_mean = np.mean(cv_scores['test_f1'])\n",
        "f1_std = np.std(cv_scores['test_f1'])\n",
        "sensitivity_mean = np.mean(cv_scores['test_sensitivity'])\n",
        "sensitivity_std = np.std(cv_scores['test_sensitivity'])\n",
        "specificity_mean = np.mean(cv_scores['test_specificity'])\n",
        "specificity_std = np.std(cv_scores['test_specificity'])\n",
        "'''\n",
        "# Get the predictions for each fold\n",
        "fold_predictions_cross = []\n",
        "for estimator, test_index in zip(cv_scores['estimator'], cv_scores['indices']['test']):\n",
        "    print(test_index)\n",
        "    X_test_fold = X_combined.tocsr()[test_index]\n",
        "    y_test_fold = y[test_index]\n",
        "    y_pred_fold = estimator.predict(X_test_fold)\n",
        "    fold_predictions_cross.append((y_test_fold, y_pred_fold))\n",
        "'''\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} Â± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} Â± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} Â± {specificity_std:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuXvF6C3zqzt",
        "outputId": "50c55048-b840-485d-8a42-e877f2fd803a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[   0    1    2 ... 6866 6868 6869]\n",
            "[ 3106  3110  3113 ... 11813 11814 11815]\n",
            "[ 4210  4211  4214 ... 16659 16660 16661]\n",
            "[ 5322  5323  5326 ... 21505 21506 21507]\n",
            "[ 6552  6553  6554 ... 26602 26603 26604]\n",
            "Cross-validation scores:\n",
            "F1 Score: 0.8682 Â± 0.0030\n",
            "Sensitivity: 0.9055 Â± 0.0113\n",
            "Specificity: 0.8862 Â± 0.0247\n"
          ]
        }
      ],
      "source": [
        "# Get the predictions for each fold\n",
        "fold_predictions_cross = []\n",
        "for estimator, test_index in zip(cv_scores['estimator'], cv_scores['indices']['test']):\n",
        "    print(test_index)\n",
        "    X_test_fold = X_combined.tocsr()[test_index]\n",
        "    y_test_fold = y[test_index]\n",
        "    y_pred_fold = estimator.predict(X_test_fold)\n",
        "    fold_predictions_cross.append((y_test_fold, y_pred_fold))\n",
        "\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} Â± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} Â± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} Â± {specificity_std:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEgD5fcZk16M"
      },
      "outputs": [],
      "source": [
        "with open('adhd-all-assessment.npy', 'wb') as f:\n",
        "    np.save(f, cv_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCGbjAUp34H3"
      },
      "source": [
        "### **Depression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_hOHYeN2XIe"
      },
      "outputs": [],
      "source": [
        "assessment_items = [\n",
        "    'Feeling sad or down in the dumps',\n",
        "    'Feeling unhappy or blue',\n",
        "    'Crying spells or tearfulness',\n",
        "    'Feeling discouraged',\n",
        "    'Feeling hopeless',\n",
        "    'Low self-esteem',\n",
        "    'Feeling worthless or inadequate',\n",
        "    'Guilt or shame',\n",
        "    'Criticizing yourself or blaming others',\n",
        "    'Difficulty making decisions',\n",
        "    'Loss of interest in family, friends or colleagues',\n",
        "    'Loneliness',\n",
        "    'Spending less time with family or friends',\n",
        "    'Loss of motivation',\n",
        "    'Loss of interest in work or other activities',\n",
        "    'Avoiding work or other activities',\n",
        "    'Loss of pleasure or satisfaction in life',\n",
        "    'Feeling tired',\n",
        "    'Difficulty sleeping or sleeping too much',\n",
        "    'Decreased or increased appetite',\n",
        "    'Loss of interest in sex',\n",
        "    'Worrying about your health',\n",
        "    'Do you have any suicidal thoughts?',\n",
        "    'Would you like to end your life?',\n",
        "    'Do you have a plan for harming yourself?'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oU7wCXDWjDt_",
        "outputId": "147002e1-5cd9-4ac1-d8bb-f40746b09135"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 187, in _run_module_as_main\n",
            "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 110, in _get_module_details\n",
            "    __import__(pkg_name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nltk/__init__.py\", line 133, in <module>\n",
            "    from nltk.collocations import *\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nltk/collocations.py\", line 36, in <module>\n",
            "    from nltk.metrics import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nltk/metrics/__init__.py\", line 38, in <module>\n",
            "    from nltk.metrics.scores import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nltk/metrics/scores.py\", line 19, in <module>\n",
            "    from nltk.util import LazyConcatenation, LazyMap\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nltk/util.py\", line 19, in <module>\n",
            "    from urllib.request import (\n",
            "  File \"/usr/lib/python3.10/urllib/request.py\", line 88, in <module>\n",
            "    import http.client\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 1395, in <module>\n",
            "    import ssl\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 99, in <module>\n",
            "    import _ssl             # if we can't import it, let the error propagate\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1002, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 945, in _find_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1439, in find_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1411, in _get_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1544, in find_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 147, in _path_stat\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-a0030fa5a6f3>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Split the data into features (X) and target (y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4628\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4629\u001b[0m         \"\"\"\n\u001b[0;32m-> 4630\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4632\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1077\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-a0030fa5a6f3>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Split the data into features (X) and target (y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-a0030fa5a6f3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Split the data into features (X) and target (y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-a0030fa5a6f3>\u001b[0m in \u001b[0;36mpreprocess_text\u001b[0;34m(text, stop_words)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_ratings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_posts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massessment_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#assessment+all\n",
        "!pip install -U scikit-learn\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.sparse import hstack\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "def generate_ratings(user_posts, assessment_items, vectorizer, stop_words):\n",
        "    user_ratings = []\n",
        "    for item in assessment_items:\n",
        "        if any(item.lower() in post.lower() for post in user_posts):\n",
        "            user_ratings.append(4)  # Item is present in user's posts, assign the highest rating\n",
        "        else:\n",
        "            user_ratings.append(0)  # Item is not present in user's posts, assign the lowest rating\n",
        "    return user_ratings\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: [preprocess_text(post, stop_words) for post in x])\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X_text = all_data['selected_posts']\n",
        "y = y_true_train\n",
        "\n",
        "# Convert the target variable to numerical labels\n",
        "y = pd.factorize(y)[0]\n",
        "\n",
        "# Convert text to Bag-of-Words representation\n",
        "vectorizer = CountVectorizer()\n",
        "X_text_vec = vectorizer.fit_transform([' '.join(posts) for posts in X_text])\n",
        "\n",
        "# Generate ratings for each data point\n",
        "X_ratings = []\n",
        "for _, row in all_data.iterrows():\n",
        "    user_posts = row['selected_posts']\n",
        "    user_ratings = generate_ratings(user_posts, checklist_items, vectorizer, stop_words)\n",
        "    X_ratings.append(user_ratings)\n",
        "\n",
        "# Convert ratings to a numpy array\n",
        "X_ratings = np.array(X_ratings)\n",
        "\n",
        "# Combine text features and rating features\n",
        "X_combined = hstack([X_text_vec, X_ratings])\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "# Define the scoring metrics\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(lambda y_true, y_pred: precision_score(y_true, y_pred))\n",
        "}\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(rf_classifier, X_combined, y, cv=5, scoring=scoring, return_estimator=True, return_indices=True)\n",
        "\n",
        "# Calculate the mean and standard deviation of the scores\n",
        "f1_mean = np.mean(cv_scores['test_f1'])\n",
        "f1_std = np.std(cv_scores['test_f1'])\n",
        "sensitivity_mean = np.mean(cv_scores['test_sensitivity'])\n",
        "sensitivity_std = np.std(cv_scores['test_sensitivity'])\n",
        "specificity_mean = np.mean(cv_scores['test_specificity'])\n",
        "specificity_std = np.std(cv_scores['test_specificity'])\n",
        "'''\n",
        "# Get the predictions for each fold\n",
        "fold_predictions_cross = []\n",
        "for estimator, test_index in zip(cv_scores['estimator'], cv_scores['indices']['test']):\n",
        "    print(test_index)\n",
        "    X_test_fold = X_combined.tocsr()[test_index]\n",
        "    y_test_fold = y[test_index]\n",
        "    y_pred_fold = estimator.predict(X_test_fold)\n",
        "    fold_predictions_cross.append((y_test_fold, y_pred_fold))\n",
        "'''\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} Â± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} Â± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} Â± {specificity_std:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MK7QQXFACWer"
      },
      "outputs": [],
      "source": [
        "with open('depression-all-assessment.npy', 'wb') as f:\n",
        "    np.save(f, cv_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "M3JbFy-sjr1w",
        "outputId": "45b0a392-bab8-4e8e-ec10-ebcbb89ecfd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-dd56294b4bcc>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Load and preprocess the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Preprocess the text data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4628\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4629\u001b[0m         \"\"\"\n\u001b[0;32m-> 4630\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4632\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1077\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-dd56294b4bcc>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Load and preprocess the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Preprocess the text data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-dd56294b4bcc>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Load and preprocess the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_posts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Preprocess the text data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#baseline+test\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "# Load the trained model and vectorizer\n",
        "model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "vectorizer = TfidfVectorizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    recall = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    precision = precision_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    return f1, recall, precision\n",
        "\n",
        "\n",
        "# Load and preprocess the training data\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Preprocess the text data\n",
        "X = vectorizer.fit_transform(all_data['selected_posts'])\n",
        "y = y_true_train\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 1000\n",
        "\n",
        "# Generate bootstrap samples and calculate scores\n",
        "bootstrap_scores_list = [bootstrap_scores(y_test, y_pred) for _ in range(num_bootstraps)]\n",
        "\n",
        "# Calculate standard deviation of scores\n",
        "f1_scores, recall_scores, precision_scores = zip(*bootstrap_scores_list)\n",
        "std_f1_score = np.std(f1_scores)\n",
        "std_recall_score = np.std(recall_scores)\n",
        "std_precision_score = np.std(precision_scores)\n",
        "\n",
        "# Print results\n",
        "print(\"Mean F1 Score:\", np.mean(f1_scores))\n",
        "print(\"Mean Recall Score:\", np.mean(recall_scores))\n",
        "print(\"Mean Precision Score:\", np.mean(precision_scores))\n",
        "print(\"Standard Deviation of F1 Scores (Bootstrap):\", std_f1_score)\n",
        "print(\"Standard Deviation of Recall Scores (Bootstrap):\", std_recall_score)\n",
        "print(\"Standard Deviation of Precision Scores (Bootstrap):\", std_precision_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PImy6IijBK3o"
      },
      "outputs": [],
      "source": [
        "with open('depression-test-simple.npy', 'wb') as f:\n",
        "    np.save(f, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "Ya8RnmbuBung",
        "outputId": "86f4afbb-925e-43b2-de77-a3e10342ea67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[   0    1    2 ... 7179 7180 7181]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "only integer scalar arrays can be converted to a scalar index",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-5ce3cb90f79d>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mX_test_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0my_test_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0my_pred_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mfold_predictions_cross\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
          ]
        }
      ],
      "source": [
        "#baseline-all\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "\n",
        "# Load the trained model and vectorizer\n",
        "model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "vectorizer = TfidfVectorizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    recall = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    precision = precision_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    return f1, recall, precision\n",
        "\n",
        "# Load and preprocess the training data\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Preprocess the text data\n",
        "X = vectorizer.fit_transform(all_data['selected_posts'])\n",
        "y = y_true_train\n",
        "\n",
        "\n",
        "# Define the scoring metrics\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(lambda y_true, y_pred: precision_score(y_true, y_pred))\n",
        "}\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(model, X, y, cv=5, scoring=scoring, return_estimator=True, return_indices=True)\n",
        "\n",
        "# Calculate the mean and standard deviation of the scores\n",
        "f1_mean = np.mean(cv_scores['test_f1'])\n",
        "f1_std = np.std(cv_scores['test_f1'])\n",
        "sensitivity_mean = np.mean(cv_scores['test_sensitivity'])\n",
        "sensitivity_std = np.std(cv_scores['test_sensitivity'])\n",
        "specificity_mean = np.mean(cv_scores['test_specificity'])\n",
        "specificity_std = np.std(cv_scores['test_specificity'])\n",
        "'''\n",
        "# Get the predictions for each fold\n",
        "fold_predictions_cross = []\n",
        "for estimator, test_index in zip(cv_scores['estimator'], cv_scores['indices']['test']):\n",
        "    print(test_index)\n",
        "    X_test_fold = X.tocsr()[test_index]\n",
        "    y_test_fold = y[test_index]\n",
        "    y_pred_fold = estimator.predict(X_test_fold)\n",
        "    fold_predictions_cross.append((y_test_fold, y_pred_fold))\n",
        "'''\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} Â± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} Â± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} Â± {specificity_std:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jCcnRy0ZK_w",
        "outputId": "425c3c59-ea6c-4508-a137-8af3d9e86a04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation scores:\n",
            "F1 Score: 0.1336 Â± 0.0741\n",
            "Sensitivity: 0.0853 Â± 0.0676\n",
            "Specificity: 0.8042 Â± 0.2291\n"
          ]
        }
      ],
      "source": [
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} Â± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} Â± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} Â± {specificity_std:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGn301aLDBiS"
      },
      "outputs": [],
      "source": [
        "with open('depression-all-simple.npy', 'wb') as f:\n",
        "    np.save(f, cv_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-MO2uyTDheO",
        "outputId": "3ff4ec13-b3ec-4969-e5db-8c05a224eae1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Standard Deviation of F1 Scores (Bootstrap): 0.002403522959625154\n",
            "Standard Deviation of Recall Scores (Bootstrap): 0.0009762779177247866\n",
            "Standard Deviation of Precision Scores (Bootstrap): 0.004221790363950144\n",
            "f1_score 0.941142753545742\n",
            "recall 0.995489533463551\n",
            "precision 0.8924324046102047\n",
            "std_f1_score 0.002403522959625154\n",
            "std_recall_score 0.0009762779177247866\n",
            "std_precision_score 0.004221790363950144\n"
          ]
        }
      ],
      "source": [
        "#assessment+test\n",
        "#!pip install -U scikit-learn\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.sparse import hstack\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "def generate_ratings(user_posts, assessment_items, vectorizer, stop_words):\n",
        "    user_ratings = []\n",
        "    for item in assessment_items:\n",
        "        if any(item.lower() in post.lower() for post in user_posts):\n",
        "            user_ratings.append(1)  # Item is present in user's posts\n",
        "        else:\n",
        "            user_ratings.append(0)  # Item is not present in user's posts\n",
        "    return user_ratings\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: [preprocess_text(post, stop_words) for post in x])\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X_text = all_data['selected_posts']\n",
        "y = y_true_train\n",
        "\n",
        "# Convert the target variable to numerical labels\n",
        "y = pd.factorize(y)[0]\n",
        "\n",
        "# Convert text to Bag-of-Words representation\n",
        "vectorizer = CountVectorizer()\n",
        "X_text_vec = vectorizer.fit_transform([' '.join(posts) for posts in X_text])\n",
        "\n",
        "# Generate ratings for each data point\n",
        "X_ratings = []\n",
        "for _, row in all_data.iterrows():\n",
        "    user_posts = row['selected_posts']\n",
        "    user_ratings = generate_ratings(user_posts, checklist_items, vectorizer, stop_words)\n",
        "    X_ratings.append(user_ratings)\n",
        "\n",
        "# Convert ratings to a numpy array\n",
        "X_ratings = np.array(X_ratings)\n",
        "\n",
        "# Combine text features and rating features\n",
        "X_combined = hstack([X_text_vec, X_ratings])\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "X_combined=X_combined.tocsr()\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#train a model\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "predictions=rf_classifier.predict(X_test)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 1000\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    recall = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    precision = precision_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    return f1, recall, precision\n",
        "\n",
        "# Generate bootstrap samples and calculate scores\n",
        "bootstrap_scores_list = [bootstrap_scores(y_test, predictions) for _ in range(num_bootstraps)]\n",
        "\n",
        "# Calculate standard deviation of scores\n",
        "f1_scores, recall_scores, precision_scores = zip(*bootstrap_scores_list)\n",
        "std_f1_score = np.std(f1_scores)\n",
        "std_recall_score = np.std(recall_scores)\n",
        "std_precision_score = np.std(precision_scores)\n",
        "\n",
        "# Print results\n",
        "print(\"Standard Deviation of F1 Scores (Bootstrap):\", std_f1_score)\n",
        "print(\"Standard Deviation of Recall Scores (Bootstrap):\", std_recall_score)\n",
        "print(\"Standard Deviation of Precision Scores (Bootstrap):\", std_precision_score)\n",
        "\n",
        "# Print results\n",
        "print(\"f1_score\", np.mean(f1_scores))\n",
        "print(\"recall\", np.mean(recall_scores))\n",
        "print(\"precision\", np.mean(precision_scores))\n",
        "print(\"std_f1_score\", std_f1_score)\n",
        "print(\"std_recall_score\", std_recall_score)\n",
        "print(\"std_precision_score\", std_precision_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-lyiohSojXk"
      },
      "outputs": [],
      "source": [
        "results=np.load('depression-test-assessment.npy', allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0iPFS6_JbcT"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import load_npz\n",
        "X_text_vec= load_npz('vectorized_selected_posts.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vK4gJTKJx5-"
      },
      "outputs": [],
      "source": [
        "X_test_best=load_npz('X_test_best.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tIOrOZNsqdN",
        "outputId": "f577406b-a4c4-4374-b064-8a969b30b3c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard Deviation of F1 Scores (Bootstrap): 0.008765145552053693\n",
            "Standard Deviation of Recall Scores (Bootstrap): 0.004480297161621923\n",
            "Standard Deviation of Precision Scores (Bootstrap): 0.063118935352238\n",
            "f1_score 0.019972680355180905\n",
            "recall 0.010106905999356363\n",
            "precision 0.996\n",
            "std_f1_score 0.008765145552053693\n",
            "std_recall_score 0.004480297161621923\n",
            "std_precision_score 0.063118935352238\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "# Generate ratings for each data point\n",
        "X_ratings = []\n",
        "for _, row in all_data.iterrows():\n",
        "    user_posts = row['selected_posts']\n",
        "    user_ratings = generate_ratings(user_posts, checklist_items, vectorizer, stop_words)\n",
        "    X_ratings.append(user_ratings)\n",
        "\n",
        "# Convert ratings to a numpy array\n",
        "X_ratings = np.array(X_ratings)\n",
        "\n",
        "# Combine text features and rating features\n",
        "X_combined = hstack([X_text_vec, X_ratings])\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_classifier_depression = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "X_combined=X_combined.tocsr()\n",
        "'''\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_text_vec, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#train a model\n",
        "rf_classifier_depression.fit(X_train, y_train)\n",
        "predictions=rf_classifier_depression.predict(X_test)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 1000\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    recall = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    precision = precision_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    return f1, recall, precision\n",
        "\n",
        "# Generate bootstrap samples and calculate scores\n",
        "bootstrap_scores_list = [bootstrap_scores(y_test, predictions) for _ in range(num_bootstraps)]\n",
        "\n",
        "# Calculate standard deviation of scores\n",
        "f1_scores, recall_scores, precision_scores = zip(*bootstrap_scores_list)\n",
        "std_f1_score = np.std(f1_scores)\n",
        "std_recall_score = np.std(recall_scores)\n",
        "std_precision_score = np.std(precision_scores)\n",
        "\n",
        "# Print results\n",
        "print(\"Standard Deviation of F1 Scores (Bootstrap):\", std_f1_score)\n",
        "print(\"Standard Deviation of Recall Scores (Bootstrap):\", std_recall_score)\n",
        "print(\"Standard Deviation of Precision Scores (Bootstrap):\", std_precision_score)\n",
        "\n",
        "# Print results\n",
        "print(\"f1_score\", np.mean(f1_scores))\n",
        "print(\"recall\", np.mean(recall_scores))\n",
        "print(\"precision\", np.mean(precision_scores))\n",
        "print(\"std_f1_score\", std_f1_score)\n",
        "print(\"std_recall_score\", std_recall_score)\n",
        "print(\"std_precision_score\", std_precision_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ofzw0St_zjf",
        "outputId": "6e8e3a58-ceef-4b4a-d888-b388800741d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#assessment+test\n",
        "#!pip install -U scikit-learn\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.sparse import hstack\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "def generate_ratings(user_posts, assessment_items, vectorizer, stop_words):\n",
        "    user_ratings = []\n",
        "    for item in assessment_items:\n",
        "        if any(item.lower() in post.lower() for post in user_posts):\n",
        "            user_ratings.append(1)  # Item is present in user's posts\n",
        "        else:\n",
        "            user_ratings.append(0)  # Item is not present in user's posts\n",
        "    return user_ratings\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: [preprocess_text(post, stop_words) for post in x])\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X_text = all_data['selected_posts']\n",
        "y = y_true_train\n",
        "\n",
        "# Convert the target variable to numerical labels\n",
        "y = pd.factorize(y)[0]\n",
        "\n",
        "# Convert text to Bag-of-Words representation\n",
        "vectorizer = CountVectorizer()\n",
        "X_text_vec = vectorizer.fit_transform([' '.join(posts) for posts in X_text])\n",
        "\n",
        "# Generate ratings for each data point\n",
        "X_ratings = []\n",
        "for _, row in all_data.iterrows():\n",
        "    user_posts = row['selected_posts']\n",
        "    user_ratings = generate_ratings(user_posts, checklist_items, vectorizer, stop_words)\n",
        "    X_ratings.append(user_ratings)\n",
        "\n",
        "# Convert ratings to a numpy array\n",
        "X_ratings = np.array(X_ratings)\n",
        "\n",
        "# Combine text features and rating features\n",
        "X_combined = hstack([X_text_vec, X_ratings])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "-Uk8h_tzp3dP",
        "outputId": "a2202b49-ecbf-439b-871f-81f98159eab4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[   0    1    2 ... 7179 7180 7181]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "X has 506773 features, but RandomForestClassifier is expecting 506798 features as input.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-3e5fb69ddff9>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX_test_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_combined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my_test_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0my_pred_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfold_predictions_cross\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \"\"\"\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[0mforce_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    642\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    444\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: X has 506773 features, but RandomForestClassifier is expecting 506798 features as input."
          ]
        }
      ],
      "source": [
        "# Get the predictions for each fold\n",
        "fold_predictions_cross = []\n",
        "for estimator, test_index in zip(cv_scores['estimator'], cv_scores['indices']['test']):\n",
        "    print(test_index)\n",
        "    X_test_fold = X_combined[test_index]\n",
        "    y_test_fold = y[test_index]\n",
        "    y_pred_fold = estimator.predict(X_test_fold)\n",
        "    print(f1_score(y_test_fold, y_pred_fold))\n",
        "    fold_predictions_cross.append((y_test_fold, y_pred_fold))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fott9aZdq-50",
        "outputId": "f1d44651-4c12-49c1-a41a-e2d7bace858d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'fit_time': array([217.37986803, 219.31158423, 231.4357605 , 224.59657741,\n",
              "        230.65932393]),\n",
              " 'score_time': array([5.11738658, 4.92695498, 4.51113391, 4.62715149, 4.2926929 ]),\n",
              " 'estimator': [RandomForestClassifier(random_state=42),\n",
              "  RandomForestClassifier(random_state=42),\n",
              "  RandomForestClassifier(random_state=42),\n",
              "  RandomForestClassifier(random_state=42),\n",
              "  RandomForestClassifier(random_state=42)],\n",
              " 'indices': {'train': (array([ 1182,  1183,  1184, ..., 26602, 26603, 26604]),\n",
              "   array([    0,     1,     2, ..., 26602, 26603, 26604]),\n",
              "   array([    0,     1,     2, ..., 26602, 26603, 26604]),\n",
              "   array([    0,     1,     2, ..., 26602, 26603, 26604]),\n",
              "   array([    0,     1,     2, ..., 21281, 21303, 21304])),\n",
              "  'test': (array([   0,    1,    2, ..., 7179, 7180, 7181]),\n",
              "   array([ 1182,  1183,  1184, ..., 11879, 11880, 11881]),\n",
              "   array([ 2283,  2285,  2286, ..., 16579, 16580, 16581]),\n",
              "   array([ 3380,  3382,  3384, ..., 21281, 21303, 21304]),\n",
              "   array([21282, 21283, 21284, ..., 26602, 26603, 26604]))},\n",
              " 'test_f1': array([0.25321464, 0.10060976, 0.10670732, 0.09202454, 0.18624642]),\n",
              " 'test_sensitivity': array([0.20611916, 0.0531401 , 0.05636071, 0.04830918, 0.10466989]),\n",
              " 'test_specificity': array([0.32820513, 0.94285714, 1.        , 0.96774194, 0.84415584])}"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJXdiZR6oq8K"
      },
      "outputs": [],
      "source": [
        "# Load the Random Forest model\n",
        "import joblib\n",
        "rf_model = joblib.load('random_forest_classifier.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdnY46l9MjFv"
      },
      "outputs": [],
      "source": [
        "y_test_best=np.load('y_test_best.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yUD905gLR2-"
      },
      "outputs": [],
      "source": [
        "predictions_test=rf_model.predict(X_test_best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv1dvfqkMqnx",
        "outputId": "a1644f29-0240-4ef3-c88a-c2666d44c31a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9566241413150147"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1_score(y_test_best, predictions_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpY8YRqyLZtJ"
      },
      "source": [
        "### **Autism**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLpFn9FKbHgp"
      },
      "outputs": [],
      "source": [
        "autism_assessment_items = {\n",
        "    1: \"S/he prefers to do things with others rather than on her/his own.\",\n",
        "    2: \"S/he prefers to do things the same way over and over again.\",\n",
        "    3: \"If s/he tries to imagine something, s/he finds it very easy to create a picture in her/his mind.\",\n",
        "    4: \"S/he frequently gets so strongly absorbed in one thing that s/he loses sight of other things.\",\n",
        "    5: \"S/he often notices small sounds when others do not.\",\n",
        "    6: \"S/he usually notices car number plates or similar strings of information.\",\n",
        "    7: \"Other people frequently tell her/him that what s/he has said is impolite, even though s/he thinks it is polite.\",\n",
        "    8: \"When s/he is reading a story, s/he can easily imagine what the characters might look like.\",\n",
        "    9: \"S/he is fascinated by dates.\",\n",
        "    10: \"In a social group, s/he can easily keep track of several different people's conversations.\",\n",
        "    11: \"S/he finds social situations easy.\",\n",
        "    12: \"S/he tends to notice details that others do not.\",\n",
        "    13: \"S/he would rather go to a library than a party.\",\n",
        "    14: \"S/he finds making up stories easy.\",\n",
        "    15: \"S/he finds her/himself drawn more strongly to people than to things.\",\n",
        "    16: \"S/he tends to have very strong interests, which s/he gets upset about if s/he can't pursue.\",\n",
        "    17: \"S/he enjoys social chit-chat.\",\n",
        "    18:\"When s/he talks, it isn't always easy for others to get a word in edgeways.\",\n",
        "    19:\"S/he is fascinated by numbers.\",\n",
        "    20:\"When s/he is reading a story, s/he finds it difficult to work out the characters' intentions.\",\n",
        "    21:\"S/he doesn't particularly enjoy reading fiction.\",\n",
        "    22:\"S/he finds it hard to make new friends.\",\n",
        "    23:\"S/he notices patterns in things all the time.\",\n",
        "    24:\"S/he would rather go to the theatre than a museum.\",\n",
        "    25:\"It does not upset him/her if his/her daily routine is disturbed.\",\n",
        "    26:\"S/he frequently finds that s/he doesn't know how to keep a conversation going.\",\n",
        "    27:\"S/he finds it easy to ''read between the lines'' when someone is talking to her/him.\",\n",
        "    28:\"S/he usually concentrates more on the whole picture, rather than the small details.\",\n",
        "    29:\"S/he is not very good at remembering phone numbers.\",\n",
        "    30:\"S/he doesn't usually notice small changes in a situation, or a person's appearance.\",\n",
        "    31: \"S/he knows how to tell if someone listening to him/her is getting bored.\",\n",
        "    32:\"S/he finds it easy to do more than one thing at once.\",\n",
        "    33:\"When s/he talks on the phone, s/he is not sure when it's her/his turn to speak.\",\n",
        "    34:\"S/he enjoys doing things spontaneously.\",\n",
        "    35:\"S/he is often the last to understand the point of a joke.\",\n",
        "    36:\"S/he finds it easy to work out what someone is thinking or feeling just by looking at their face.\",\n",
        "    37:\"If there is an interruption, s/he can switch back to what s/he was doing very quickly.\",\n",
        "    38:\"S/he is good at social chit-chat.\",\n",
        "    39:\"People often tell her/him that s/he keeps going on and on about the same thing.\",\n",
        "    40:\"When s/he was younger, s/he used to enjoy playing games involving pretending with other children.\",\n",
        "    41:\"S/he likes to collect information about categories of things (e.g. types of car, types of bird, types of train, types of plant, etc.).\",\n",
        "    42:\"S/he finds it difficult to imagine what it would be like to be someone else.\",\n",
        "    43:\"S/he likes to plan any activities s/he participates in carefully.\",\n",
        "    44:\"S/he enjoys social occasions.\",\n",
        "    45:\"S/he finds it difficult to work out people's intentions.\",\n",
        "    46:\"New situations make him/her anxious.\",\n",
        "    47:\"S/he enjoys meeting new people.\",\n",
        "    48:\"S/he is a good diplomat.\",\n",
        "    49:\"S/he is not very good at remembering people's date of birth.\",\n",
        "    50:\"S/he finds it very easy to play games with children that involve pretending.\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zICyHX_fLdfb",
        "outputId": "701ffc47-4f04-465f-b4a6-b054c0a359b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation scores:\n",
            "F1 Score: 0.0055 Â± 0.0068\n",
            "Sensitivity: 0.0028 Â± 0.0034\n",
            "Specificity: 0.4000 Â± 0.4899\n"
          ]
        }
      ],
      "source": [
        "#assessment+all\n",
        "!pip install -U scikit-learn\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "def generate_ratings(user_posts, autism_assessment_items, vectorizer, stop_words):\n",
        "    user_ratings = []\n",
        "    for item_number, item in autism_assessment_items.items():\n",
        "        if any(item.lower() in post.lower() for post in user_posts):\n",
        "            if item_number in [2, 4, 5, 6, 7, 9, 12, 13, 16, 18, 19, 20, 21, 22, 23, 26, 33, 35, 39, 41, 42, 43, 45, 46]:\n",
        "                user_ratings.append(1)  # 'Definitely agree' or 'slightly agree' responses scored 1 point\n",
        "            else:\n",
        "                user_ratings.append(0)  # 'Definitely disagree' or 'slightly disagree' responses scored 0 points\n",
        "        else:\n",
        "            if item_number in [1, 3, 8, 10, 11, 14, 15, 17, 24, 25, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 40, 44, 47, 48, 49, 50]:\n",
        "                user_ratings.append(1)  # 'Definitely disagree' or 'slightly disagree' responses scored 1 point\n",
        "            else:\n",
        "                user_ratings.append(0)  # 'Definitely agree' or 'slightly agree' responses scored 0 points\n",
        "    return user_ratings\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: [preprocess_text(post, stop_words) for post in x])\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X_text = all_data['selected_posts']\n",
        "y = y_true_train\n",
        "\n",
        "# Convert the target variable to numerical labels\n",
        "y = pd.factorize(y)[0]\n",
        "\n",
        "# Convert text to Bag-of-Words representation\n",
        "vectorizer = CountVectorizer()\n",
        "X_text_vec = vectorizer.fit_transform([' '.join(posts) for posts in X_text])\n",
        "\n",
        "# Generate ratings for each data point\n",
        "X_ratings = []\n",
        "for _, row in all_data.iterrows():\n",
        "    user_posts = row['selected_posts']\n",
        "    user_ratings = generate_ratings(user_posts, autism_assessment_items, vectorizer, stop_words)\n",
        "    X_ratings.append(user_ratings)\n",
        "\n",
        "# Convert ratings to a numpy array\n",
        "X_ratings = np.array(X_ratings)\n",
        "\n",
        "# Combine text features and rating features\n",
        "X_combined = hstack([X_text_vec, X_ratings])\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=5, random_state=42)\n",
        "\n",
        "# Define the scoring metrics\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(lambda y_true, y_pred: precision_score(y_true, y_pred))\n",
        "}\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(rf_classifier, X_combined, y, cv=5, scoring=scoring, return_estimator=True, return_indices=True)\n",
        "\n",
        "# Calculate the mean and standard deviation of the scores\n",
        "f1_mean = np.mean(cv_scores['test_f1'])\n",
        "f1_std = np.std(cv_scores['test_f1'])\n",
        "sensitivity_mean = np.mean(cv_scores['test_sensitivity'])\n",
        "sensitivity_std = np.std(cv_scores['test_sensitivity'])\n",
        "specificity_mean = np.mean(cv_scores['test_specificity'])\n",
        "specificity_std = np.std(cv_scores['test_specificity'])\n",
        "'''\n",
        "# Get the predictions for each fold\n",
        "fold_predictions_cross = []\n",
        "for estimator, test_index in zip(cv_scores['estimator'], cv_scores['indices']['test']):\n",
        "    print(test_index)\n",
        "    X_test_fold = X_combined.tocsr()[test_index]\n",
        "    y_test_fold = y[test_index]\n",
        "    y_pred_fold = estimator.predict(X_test_fold)\n",
        "    fold_predictions_cross.append((y_test_fold, y_pred_fold))\n",
        "'''\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} Â± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} Â± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} Â± {specificity_std:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EupETxg4gGCb"
      },
      "outputs": [],
      "source": [
        "with open('autism-all-assessment.npy', 'wb') as f:\n",
        "    np.save(f, cv_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRm60aH2eY6l",
        "outputId": "b677a5e8-649e-4603-d591-b6534fdeb014"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard Deviation of F1 Scores (Bootstrap): 0.0\n",
            "Standard Deviation of Recall Scores (Bootstrap): 0.0\n",
            "Standard Deviation of Precision Scores (Bootstrap): 0.0\n",
            "f1_score 0.0\n",
            "recall 0.0\n",
            "precision 0.0\n",
            "std_f1_score 0.0\n",
            "std_recall_score 0.0\n",
            "std_precision_score 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "#assessment+test\n",
        "!pip install -U scikit-learn\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "def preprocess_text(text, stop_words):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "def generate_ratings(user_posts, autism_assessment_items, vectorizer, stop_words):\n",
        "    user_ratings = []\n",
        "    for item_number, item in autism_assessment_items.items():\n",
        "        if any(item.lower() in post.lower() for post in user_posts):\n",
        "            if item_number in [2, 4, 5, 6, 7, 9, 12, 13, 16, 18, 19, 20, 21, 22, 23, 26, 33, 35, 39, 41, 42, 43, 45, 46]:\n",
        "                user_ratings.append(1)  # 'Definitely agree' or 'slightly agree' responses scored 1 point\n",
        "            else:\n",
        "                user_ratings.append(0)  # 'Definitely disagree' or 'slightly disagree' responses scored 0 points\n",
        "        else:\n",
        "            if item_number in [1, 3, 8, 10, 11, 14, 15, 17, 24, 25, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 40, 44, 47, 48, 49, 50]:\n",
        "                user_ratings.append(1)  # 'Definitely disagree' or 'slightly disagree' responses scored 1 point\n",
        "            else:\n",
        "                user_ratings.append(0)  # 'Definitely agree' or 'slightly agree' responses scored 0 points\n",
        "    return user_ratings\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: [preprocess_text(post, stop_words) for post in x])\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X_text = all_data['selected_posts']\n",
        "y = y_true_train\n",
        "\n",
        "# Convert the target variable to numerical labels\n",
        "y = pd.factorize(y)[0]\n",
        "\n",
        "# Convert text to Bag-of-Words representation\n",
        "vectorizer = CountVectorizer()\n",
        "X_text_vec = vectorizer.fit_transform([' '.join(posts) for posts in X_text])\n",
        "\n",
        "# Generate ratings for each data point\n",
        "X_ratings = []\n",
        "for _, row in all_data.iterrows():\n",
        "    user_posts = row['selected_posts']\n",
        "    user_ratings = generate_ratings(user_posts, autism_assessment_items, vectorizer, stop_words)\n",
        "    X_ratings.append(user_ratings)\n",
        "\n",
        "# Convert ratings to a numpy array\n",
        "X_ratings = np.array(X_ratings)\n",
        "\n",
        "# Combine text features and rating features\n",
        "X_combined = hstack([X_text_vec, X_ratings])\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=5)\n",
        "X_combined = X_combined.tocsr()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.1)\n",
        "\n",
        "# Train a model\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "predictions = rf_classifier.predict(X_test)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 100\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    recall = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    precision = precision_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    return f1, recall, precision\n",
        "\n",
        "# Generate bootstrap samples and calculate scores\n",
        "bootstrap_scores_list = [bootstrap_scores(y_test, predictions) for _ in range(num_bootstraps)]\n",
        "\n",
        "# Calculate standard deviation of scores\n",
        "f1_scores, recall_scores, precision_scores = zip(*bootstrap_scores_list)\n",
        "std_f1_score = np.std(f1_scores)\n",
        "std_recall_score = np.std(recall_scores)\n",
        "std_precision_score = np.std(precision_scores)\n",
        "\n",
        "# Print results\n",
        "print(\"Standard Deviation of F1 Scores (Bootstrap):\", std_f1_score)\n",
        "print(\"Standard Deviation of Recall Scores (Bootstrap):\", std_recall_score)\n",
        "print(\"Standard Deviation of Precision Scores (Bootstrap):\", std_precision_score)\n",
        "print(\"f1_score\", np.mean(f1_scores))\n",
        "print(\"recall\", np.mean(recall_scores))\n",
        "print(\"precision\", np.mean(precision_scores))\n",
        "print(\"std_f1_score\", std_f1_score)\n",
        "print(\"std_recall_score\", std_recall_score)\n",
        "print(\"std_precision_score\", std_precision_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fydzmaDxghzJ"
      },
      "outputs": [],
      "source": [
        "with open('autism-test-assessment.npy', 'wb') as f:\n",
        "    np.save(f, cv_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t4Kw2Swgnya",
        "outputId": "b0bf3dee-57f8-4272-e6fe-a0809c9d9d79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Cross-validation scores:\n",
            "F1 Score: 0.1354 Â± 0.0524\n",
            "Sensitivity: 0.0796 Â± 0.0286\n",
            "Specificity: 0.8118 Â± 0.3520\n"
          ]
        }
      ],
      "source": [
        "#baseline-all\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "\n",
        "# Load the trained model and vectorizer\n",
        "model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "vectorizer = TfidfVectorizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    recall = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    precision = precision_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    return f1, recall, precision\n",
        "\n",
        "# Load and preprocess the training data\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Preprocess the text data\n",
        "X = vectorizer.fit_transform(all_data['selected_posts'])\n",
        "y = y_true_train\n",
        "\n",
        "\n",
        "# Define the scoring metrics\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(lambda y_true, y_pred: precision_score(y_true, y_pred))\n",
        "}\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(model, X, y, cv=5, scoring=scoring, return_estimator=True, return_indices=True)\n",
        "\n",
        "# Calculate the mean and standard deviation of the scores\n",
        "f1_mean = np.mean(cv_scores['test_f1'])\n",
        "f1_std = np.std(cv_scores['test_f1'])\n",
        "sensitivity_mean = np.mean(cv_scores['test_sensitivity'])\n",
        "sensitivity_std = np.std(cv_scores['test_sensitivity'])\n",
        "specificity_mean = np.mean(cv_scores['test_specificity'])\n",
        "specificity_std = np.std(cv_scores['test_specificity'])\n",
        "'''\n",
        "# Get the predictions for each fold\n",
        "fold_predictions_cross = []\n",
        "for estimator, test_index in zip(cv_scores['estimator'], cv_scores['indices']['test']):\n",
        "    print(test_index)\n",
        "    X_test_fold = X.tocsr()[test_index]\n",
        "    y_test_fold = y[test_index]\n",
        "    y_pred_fold = estimator.predict(X_test_fold)\n",
        "    fold_predictions_cross.append((y_test_fold, y_pred_fold))\n",
        "'''\n",
        "print(\"Cross-validation scores:\")\n",
        "print(f\"F1 Score: {f1_mean:.4f} Â± {f1_std:.4f}\")\n",
        "print(f\"Sensitivity: {sensitivity_mean:.4f} Â± {sensitivity_std:.4f}\")\n",
        "print(f\"Specificity: {specificity_mean:.4f} Â± {specificity_std:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojh_YWItgoTd"
      },
      "outputs": [],
      "source": [
        "with open('autism-all-simple.npy', 'wb') as f:\n",
        "    np.save(f, cv_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9GJwPCAgxrO",
        "outputId": "0f73f947-309f-4609-b725-37e515062c3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean F1 Score: 0.06989712821367253\n",
            "Mean Recall Score: 0.036425017886209\n",
            "Mean Precision Score: 0.998\n",
            "Standard Deviation of F1 Scores (Bootstrap): 0.027485387266423675\n",
            "Standard Deviation of Recall Scores (Bootstrap): 0.014806910557304884\n",
            "Standard Deviation of Precision Scores (Bootstrap): 0.044676615807377355\n"
          ]
        }
      ],
      "source": [
        "#baseline+test\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "!python -m nltk.downloader stopwords\n",
        "\n",
        "# Load the trained model and vectorizer\n",
        "model = LogisticRegression(multi_class='multinomial', solver='saga')\n",
        "vectorizer = TfidfVectorizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Function to calculate F1, recall, and precision scores\n",
        "def bootstrap_scores(true_labels, preds):\n",
        "    indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n",
        "    bootstrap_true_labels = np.take(true_labels, indices)\n",
        "    bootstrap_preds = np.take(preds, indices)\n",
        "    f1 = f1_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    recall = recall_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    precision = precision_score(bootstrap_true_labels, bootstrap_preds)\n",
        "    return f1, recall, precision\n",
        "\n",
        "\n",
        "# Load and preprocess the training data\n",
        "all_data['selected_posts'] = all_data['selected_posts'].apply(lambda x: ' '.join([word for post in x for word in post.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Preprocess the text data\n",
        "X = vectorizer.fit_transform(all_data['selected_posts'])\n",
        "y = y_true_train\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 1000\n",
        "\n",
        "# Generate bootstrap samples and calculate scores\n",
        "bootstrap_scores_list = [bootstrap_scores(y_test, y_pred) for _ in range(num_bootstraps)]\n",
        "\n",
        "# Calculate standard deviation of scores\n",
        "f1_scores, recall_scores, precision_scores = zip(*bootstrap_scores_list)\n",
        "std_f1_score = np.std(f1_scores)\n",
        "std_recall_score = np.std(recall_scores)\n",
        "std_precision_score = np.std(precision_scores)\n",
        "\n",
        "# Print results\n",
        "print(\"Mean F1 Score:\", np.mean(f1_scores))\n",
        "print(\"Mean Recall Score:\", np.mean(recall_scores))\n",
        "print(\"Mean Precision Score:\", np.mean(precision_scores))\n",
        "print(\"Standard Deviation of F1 Scores (Bootstrap):\", std_f1_score)\n",
        "print(\"Standard Deviation of Recall Scores (Bootstrap):\", std_recall_score)\n",
        "print(\"Standard Deviation of Precision Scores (Bootstrap):\", std_precision_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTfJ1Tnygy-1"
      },
      "outputs": [],
      "source": [
        "with open('autism-test-simple.npy', 'wb') as f:\n",
        "    np.save(f, y_pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
